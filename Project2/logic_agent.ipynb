{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T20:10:18.095942Z",
     "start_time": "2025-10-04T20:10:18.003545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import Enum, auto\n",
    "from typing import List, Union, Dict, Tuple, Optional, Any, TypeAlias, Iterable, Callable\n",
    "import re\n",
    "\n",
    "#Parameters\n",
    "filepath = \"Caves/easy/path_e1.txt\"\n",
    "\n",
    "# <editor-fold desc=\"Semantics and structure for FOL\">\n",
    "\n",
    "class TokenType(Enum):\n",
    "    XOR = auto()\n",
    "    OR = auto()\n",
    "    AND = auto()\n",
    "    NOT = auto()\n",
    "    ALL = auto()\n",
    "    ANY = auto()\n",
    "    IMPLIES = auto()\n",
    "    IFF = auto()\n",
    "    IN = auto()\n",
    "\n",
    "    TRUE = auto()\n",
    "    FALSE = auto()\n",
    "    IDENT = auto()\n",
    "\n",
    "    LPAREN = auto()\n",
    "    RPAREN = auto()\n",
    "    COMMA  = auto()\n",
    "\n",
    "    def __str__(self): return self.name\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Token:\n",
    "    type: TokenType\n",
    "    name: Optional[str] = None  # used for variables quantifiers and predicates\n",
    "\n",
    "class Lexer:\n",
    "    _whitespace = re.compile(r\"\\s+\")\n",
    "    _identifier = re.compile(r\"[A-Za-z_][A-Za-z0-9_]*\")\n",
    "\n",
    "    SYMBOLS = [\n",
    "        (\"(\", TokenType.LPAREN),\n",
    "        (\")\", TokenType.RPAREN),\n",
    "        (\",\", TokenType.COMMA),\n",
    "    ]\n",
    "\n",
    "    # keywords, case-sensitive\n",
    "    KEYWORDS = {\n",
    "        \"TRUE\": TokenType.TRUE,\n",
    "        \"FALSE\": TokenType.FALSE,\n",
    "\n",
    "        \"AND\": TokenType.AND,\n",
    "        \"OR\": TokenType.OR,\n",
    "        \"XOR\": TokenType.XOR,\n",
    "        \"NOT\": TokenType.NOT,\n",
    "\n",
    "        \"IMPLIES\": TokenType.IMPLIES,\n",
    "        \"IFF\": TokenType.IFF,\n",
    "\n",
    "        \"ALL\": TokenType.ALL,\n",
    "        \"ANY\": TokenType.ANY,\n",
    "        \"IN\": TokenType.IN,\n",
    "    }\n",
    "\n",
    "    def tokenize(self, text: str) -> List[Token]:\n",
    "        tokens: List[Token] = []\n",
    "        i = 0\n",
    "        length = len(text)\n",
    "\n",
    "        while i < length:\n",
    "            # skip whitespace\n",
    "            current = self._whitespace.match(text, i)\n",
    "            if current:\n",
    "                i = current.end()\n",
    "                if i >= length:\n",
    "                    break\n",
    "\n",
    "            matched_symbol = False\n",
    "            for symbol, token_type in self.SYMBOLS:\n",
    "                if text.startswith(symbol, i):\n",
    "                    tokens.append(Token(token_type))\n",
    "                    i += len(symbol)\n",
    "                    matched_symbol = True\n",
    "                    break\n",
    "            if matched_symbol:\n",
    "                continue\n",
    "\n",
    "            # Identifier / keyword\n",
    "            current = self._identifier.match(text, i)\n",
    "            if current:\n",
    "                lex = current.group(0)\n",
    "                i = current.end()\n",
    "\n",
    "                # Keyword\n",
    "                token_type = self.KEYWORDS.get(lex)\n",
    "                if token_type is not None:\n",
    "                    tokens.append(Token(token_type))\n",
    "                else:\n",
    "                    tokens.append(Token(TokenType.IDENT, name=lex))\n",
    "                continue\n",
    "\n",
    "            # fallback\n",
    "            raise ValueError(f\"Unexpected character at {i}: {repr(text[i])}\")\n",
    "\n",
    "        return tokens\n",
    "\n",
    "# Terms\n",
    "class LogicTerminal(Enum):\n",
    "    U = auto()  # Unknown\n",
    "    F = auto()  # False\n",
    "    T = auto()  # True\n",
    "\n",
    "    def __str__(self):\n",
    "        if self is LogicTerminal.U: return \"Unknown\"\n",
    "        if self is LogicTerminal.F: return \"False\"\n",
    "        if self is LogicTerminal.T: return \"True\"\n",
    "        return \"NULL\"\n",
    "\n",
    "    def __bool__(self): return self is LogicTerminal.T\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Variable:\n",
    "    name: Any\n",
    "    def __str__(self) -> str: return str(self.name)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Constant:\n",
    "    value: LogicTerminal = LogicTerminal.U\n",
    "    def __str__(self) -> str: return str(self.value)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Predicate:\n",
    "    name: str\n",
    "    args: Tuple[Any, ...] = field(default_factory=tuple)  # must be immutable for hashing\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}({', '.join(map(str, self.args))})\"\n",
    "\n",
    "\n",
    "class LogicOperator(Enum):\n",
    "    XOR = auto()\n",
    "    AND = auto()\n",
    "    OR = auto()\n",
    "    IFF = auto()\n",
    "    IMPLIES = auto()\n",
    "\n",
    "    def __str__(self): return self.name\n",
    "\n",
    "class Quantifier(Enum):\n",
    "    ANY = auto()\n",
    "    ALL = auto()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Not:\n",
    "    child: Any\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Operator:\n",
    "    nodeType: LogicOperator\n",
    "    children: List[Any] = field(default_factory=list)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class QuantifierExpression:\n",
    "    quantifier: Quantifier\n",
    "    variables: Tuple[Variable, ...]\n",
    "    domain: Any\n",
    "    expression: 'Expression'\n",
    "\n",
    "Term: TypeAlias = Union[Variable, Constant, LogicTerminal, None]\n",
    "Expression: TypeAlias = Union[Predicate, Not, Operator, QuantifierExpression, Constant, Variable]\n",
    "ParseNode = Union[Term, Expression]\n",
    "\n",
    "\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.expression: List[Token] = []\n",
    "        self.parse_index = 0\n",
    "\n",
    "    def __call__(self, arg: Union[str,List[Token]]):\n",
    "        if isinstance(arg, str):\n",
    "            lex = Lexer()\n",
    "            self.expression = lex.tokenize(arg)\n",
    "        elif isinstance(arg, list):\n",
    "            self.expression = arg\n",
    "        return self.parse(self.expression)\n",
    "\n",
    "    def parse(self, tokens: List[Token]) -> ParseNode:\n",
    "        self.expression = tokens\n",
    "        self.parse_index = 0\n",
    "        return self.parse_expression()\n",
    "\n",
    "    def peek(self, k=0) -> Optional[Token]:\n",
    "        i = self.parse_index + k\n",
    "        return self.expression[i] if 0 <= i < len(self.expression) else None\n",
    "\n",
    "    def peek_is(self, t: TokenType) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if next token exists and is of a certain type\n",
    "        \"\"\"\n",
    "        tok = self.peek()\n",
    "        return tok is not None and tok.type is t\n",
    "\n",
    "    def eat(self) -> Optional[Token]:\n",
    "        tok = self.peek()\n",
    "        if tok is not None:\n",
    "            self.parse_index += 1\n",
    "        return tok\n",
    "\n",
    "    def expect(self, token_type: TokenType) -> Token:\n",
    "        tok = self.eat()\n",
    "        if tok is None or tok.type is not token_type:\n",
    "            raise ValueError(f\"Expected {token_type}, got {tok}\")\n",
    "        return tok\n",
    "\n",
    "    def parse_expression(self) -> ParseNode:\n",
    "        node = self._parse_iff()\n",
    "        if self.peek() is not None:\n",
    "            raise ValueError(f\"Expression not empty after parsing\")\n",
    "        return node\n",
    "\n",
    "    def _parse_iff(self) -> ParseNode:\n",
    "        node = self._parse_implies()\n",
    "        while self.peek_is(TokenType.IFF):\n",
    "            self.eat()\n",
    "            rhs = self._parse_implies()\n",
    "            node = self._reduce_iff(node, rhs)\n",
    "        return node\n",
    "\n",
    "    def _parse_implies(self) -> ParseNode:\n",
    "        left = self._parse_xor()\n",
    "        if self.peek_is(TokenType.IMPLIES):\n",
    "            self.eat()\n",
    "            right = self._parse_implies()  # right-assoc\n",
    "            return self.reduce_implies(left, right)\n",
    "        return left\n",
    "\n",
    "    def _parse_xor(self) -> ParseNode:\n",
    "        node = self._parse_or()\n",
    "        while self.peek_is(TokenType.XOR):\n",
    "            self.eat()\n",
    "            rhs = self._parse_or()\n",
    "            node = Operator(nodeType=LogicOperator.XOR, children=[node, rhs])\n",
    "        return node\n",
    "\n",
    "    def _parse_or(self) -> ParseNode:\n",
    "        node = self._parse_and()\n",
    "        while self.peek_is(TokenType.OR):\n",
    "            self.eat()\n",
    "            rhs = self._parse_and()\n",
    "            node = Operator(nodeType=LogicOperator.OR, children=[node, rhs])\n",
    "        return node\n",
    "\n",
    "    def _parse_and(self) -> ParseNode:\n",
    "        node = self._parse_not()\n",
    "        while self.peek_is(TokenType.AND):\n",
    "            self.eat()\n",
    "            rhs = self._parse_not()\n",
    "            node = Operator(nodeType=LogicOperator.AND, children=[node, rhs])\n",
    "        return node\n",
    "\n",
    "    def _parse_not(self) -> ParseNode:\n",
    "        if self.peek_is(TokenType.NOT):\n",
    "            self.eat()\n",
    "            return Not(child=self._parse_not())\n",
    "        return self._parse_atom()\n",
    "\n",
    "    def _parse_atom(self) -> ParseNode:\n",
    "        tok = self.peek()\n",
    "        if tok is None:\n",
    "            raise ValueError(\"Unexpected end of expression\")\n",
    "\n",
    "        # booleans\n",
    "        if tok.type is TokenType.TRUE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.T)\n",
    "        if tok.type is TokenType.FALSE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.F)\n",
    "\n",
    "        #'(' expr ')'\n",
    "        if tok.type is TokenType.LPAREN:\n",
    "            self.eat()\n",
    "            node = self._parse_iff()\n",
    "            self.expect(TokenType.RPAREN)\n",
    "            return node\n",
    "\n",
    "        # Quantifier (ALL/ANY)\n",
    "        if self.peek_is(TokenType.ALL) or self.peek_is(TokenType.ANY):\n",
    "            return self._parse_quantifier()\n",
    "\n",
    "        # Predicate or variable: IDENT [ '(' args ')' ]\n",
    "        if tok.type is TokenType.IDENT:\n",
    "            ident = self.eat()\n",
    "            name = ident.name\n",
    "\n",
    "            if self.peek_is(TokenType.LPAREN):\n",
    "                self.eat()\n",
    "                args: List[Term] = []\n",
    "                if not self.peek_is(TokenType.RPAREN):\n",
    "                    while True:\n",
    "                        args.append(self._parse_term())\n",
    "                        if self.peek_is(TokenType.COMMA):\n",
    "                            self.eat()\n",
    "                            continue\n",
    "                        break\n",
    "                self.expect(TokenType.RPAREN)\n",
    "                return Predicate(name=name, args=tuple(args))\n",
    "\n",
    "            # variable\n",
    "            return Variable(name=name)\n",
    "\n",
    "        raise ValueError(f\"Unexpected token in atom: {tok}\")\n",
    "\n",
    "    def _parse_term(self) -> Term:\n",
    "        tok = self.peek()\n",
    "        if tok is None:\n",
    "            raise ValueError(\"Unexpected end of arguments\")\n",
    "        if tok.type is TokenType.TRUE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.T)\n",
    "        if tok.type is TokenType.FALSE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.F)\n",
    "        if tok.type is TokenType.IDENT:\n",
    "            return Variable(name=self.eat().name)\n",
    "        if tok.type is TokenType.LPAREN:\n",
    "            raise ValueError(\"Nested predicate arguments not supported\")\n",
    "        raise ValueError(f\"Invalid token: {tok}\")\n",
    "\n",
    "    def _parse_quantifier(self) -> ParseNode:\n",
    "        quantifier_token = self.eat()\n",
    "        quantifier = Quantifier.ALL if quantifier_token.type is TokenType.ALL else Quantifier.ANY\n",
    "\n",
    "        # Variables: IDENT or '(' IDENT (',' IDENT)* ')'\n",
    "        variables: List[Variable] = []\n",
    "        if self.peek_is(TokenType.LPAREN):\n",
    "            self.eat()\n",
    "            while True:\n",
    "                ident = self.expect(TokenType.IDENT)\n",
    "                variables.append(Variable(name=ident.name))\n",
    "                if self.peek_is(TokenType.COMMA):\n",
    "                    self.eat()\n",
    "                    continue\n",
    "                break\n",
    "            self.expect(TokenType.RPAREN)\n",
    "        else:\n",
    "            ident = self.expect(TokenType.IDENT)\n",
    "            variables.append(Variable(name=ident.name))\n",
    "\n",
    "        # IN domain\n",
    "        self.expect(TokenType.IN)\n",
    "        domain_token = self.expect(TokenType.IDENT)\n",
    "        domain = domain_token.name\n",
    "\n",
    "        if self.peek_is(TokenType.LPAREN):\n",
    "            self.eat()\n",
    "            body = self._parse_iff()\n",
    "            self.expect(TokenType.RPAREN)\n",
    "        else:\n",
    "            body = self._parse_iff()\n",
    "\n",
    "        return QuantifierExpression(quantifier=quantifier, variables=tuple(variables), domain=domain, expression=body)\n",
    "\n",
    "    # Reductions for IMPLIES/IFF\n",
    "    @staticmethod\n",
    "    def reduce_implies(p: ParseNode, q: ParseNode) -> ParseNode:\n",
    "        # p -> q  ==  (!p) OR q\n",
    "        return Operator(nodeType=LogicOperator.OR, children=[Not(p), q])\n",
    "\n",
    "    def _reduce_iff(self, p: ParseNode, q: ParseNode) -> ParseNode:\n",
    "        # p <-> q  ==  (p -> q) AND (q -> p)\n",
    "        return Operator(\n",
    "            nodeType=LogicOperator.AND,\n",
    "            children=[self.reduce_implies(p, q), self.reduce_implies(q, p)]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def pretty_print(node: ParseNode, indent: str = \"\", is_last: bool = True):\n",
    "        branch = \"\\\\-- \" if is_last else \"| \"\n",
    "        next_indent = indent + (\"    \" if is_last else \"|   \")\n",
    "\n",
    "        # Operator\n",
    "        if isinstance(node, Operator):\n",
    "            label = str(node.nodeType.name)\n",
    "            print(indent + branch + label)\n",
    "            for i, child in enumerate(node.children):\n",
    "                Parser.pretty_print(child, next_indent, i == len(node.children) - 1)\n",
    "            return\n",
    "\n",
    "        # NOT\n",
    "        if isinstance(node, Not):\n",
    "            print(indent + branch + \"NOT\")\n",
    "            Parser.pretty_print(node.child, next_indent, True)\n",
    "            return\n",
    "\n",
    "        # Predicate\n",
    "        if isinstance(node, Predicate):\n",
    "            print(indent + branch + str(node))\n",
    "            return\n",
    "\n",
    "        # Constant (LogicTerminal)\n",
    "        if isinstance(node, Constant):\n",
    "            print(indent + branch + str(node.value))\n",
    "            return\n",
    "\n",
    "        # Variable\n",
    "        if isinstance(node, Variable):\n",
    "            print(indent + branch + f\"Variable({node.name})\")\n",
    "            return\n",
    "\n",
    "        # Quantifier\n",
    "        if isinstance(node, QuantifierExpression):\n",
    "            quantifier_name = str(node.quantifier.name)\n",
    "            variables_str = \", \".join(v.name for v in node.variables)\n",
    "            domain_str = node.domain\n",
    "            label = f\"{quantifier_name} {variables_str} IN {domain_str}\"\n",
    "            print(indent + branch + label)\n",
    "            Parser.pretty_print(node.expression, next_indent, True)\n",
    "            return\n",
    "\n",
    "        # LogicTerminal\n",
    "        if isinstance(node, LogicTerminal):\n",
    "            print(indent + branch + str(node))\n",
    "            return\n",
    "\n",
    "        # Fallback\n",
    "        print(indent + branch + f\"{node}\")\n",
    "\n",
    "\n",
    "\n",
    "class ExpressionEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluate an AST\n",
    "    - For propositional variables: look up in variable_environment (by variable name)\n",
    "    - For predicates consult predicate_table\n",
    "    - For quantifiers need domains\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: ParseNode,\n",
    "        variable_environment: Optional[Dict[str, LogicTerminal]] = None,\n",
    "        predicate_table: Optional[Dict[Tuple[str, Tuple[Any, ...]], LogicTerminal]] = None,\n",
    "        domains: Optional[Dict[str, Union[Iterable,Callable]]] = None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.variable_environment = variable_environment or {}\n",
    "        self.predicate_table = predicate_table or {}\n",
    "        self.domains = domains or {}\n",
    "\n",
    "        # current variable bindings\n",
    "        self.bindings: Dict[str, Any] = {}\n",
    "\n",
    "        self.evaluation: LogicTerminal = self.eval(root)\n",
    "\n",
    "    def _resolve_domain(self, name: str) -> Iterable[Any]:\n",
    "        if name not in self.domains:\n",
    "            raise ValueError(f\"Domain '{name}' not provided.\")\n",
    "        domain = self.domains[name]\n",
    "        # If callable, pass current bindings so it can depend on bound vars\n",
    "        return domain(self.bindings) if callable(domain) else domain\n",
    "\n",
    "    @staticmethod\n",
    "    def implies(p: ParseNode, q: ParseNode) -> ParseNode:\n",
    "        return Operator(LogicOperator.OR, [Not(p), q])\n",
    "\n",
    "    @staticmethod\n",
    "    def equivalence(p: ParseNode, q: ParseNode) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        Evaluate (p -> q) ∧ (q -> p).\n",
    "        \"\"\"\n",
    "        new_expression_tree = Operator(LogicOperator.AND, [ExpressionEvaluator.implies(p, q), ExpressionEvaluator.implies(q, p)])\n",
    "        return ExpressionEvaluator(new_expression_tree).evaluation\n",
    "\n",
    "    @staticmethod\n",
    "    def _not(arg: LogicTerminal) -> LogicTerminal:\n",
    "        match arg:\n",
    "            case LogicTerminal.F: return LogicTerminal.T\n",
    "            case LogicTerminal.T: return LogicTerminal.F\n",
    "            case _: return LogicTerminal.U\n",
    "\n",
    "    @staticmethod\n",
    "    def _and(args: List[LogicTerminal]) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        True IFF all entries are True. If at least one is false, false, if at least one is unknown, unknown\n",
    "        \"\"\"\n",
    "        if any(arg is LogicTerminal.F for arg in args): return LogicTerminal.F\n",
    "        if any(arg is LogicTerminal.U for arg in args): return LogicTerminal.U\n",
    "        return LogicTerminal.T\n",
    "\n",
    "    @staticmethod\n",
    "    def _or(args: List[LogicTerminal]) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        True IFF any entries are True. Then Unknown if any are unknown, false otherwise\n",
    "        \"\"\"\n",
    "        if any(arg is LogicTerminal.T for arg in args): return LogicTerminal.T\n",
    "        if any(arg is LogicTerminal.U for arg in args): return LogicTerminal.U\n",
    "        return LogicTerminal.F\n",
    "\n",
    "    @staticmethod\n",
    "    def _xor(args: List[LogicTerminal]) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        True if only one entry is true, with no unknown entries.\n",
    "        If the number of true args is <=1 then the evaluation can be unknown if unknown is present.\n",
    "        Otherwise false\n",
    "        \"\"\"\n",
    "        true_count = sum(int(bool(arg)) for arg in args)\n",
    "        if true_count > 1:\n",
    "            return LogicTerminal.F\n",
    "        if LogicTerminal.U in args:\n",
    "            return LogicTerminal.U\n",
    "        return LogicTerminal.T if true_count == 1 else LogicTerminal.F\n",
    "\n",
    "\n",
    "\n",
    "    def eval(self, node: ParseNode) -> LogicTerminal:\n",
    "        # Constants / raw terminals\n",
    "        if isinstance(node, Constant): return node.value\n",
    "        if isinstance(node, LogicTerminal): return node\n",
    "\n",
    "        # Propositional variable alone\n",
    "        if isinstance(node, Variable):\n",
    "            return self._eval_variable(node)\n",
    "\n",
    "        # Predicates (possibly with vars)\n",
    "        if isinstance(node, Predicate):\n",
    "            return self._eval_predicate(node)\n",
    "\n",
    "        # Unary NOT\n",
    "        if isinstance(node, Not):\n",
    "            return self._not(self.eval(node.child))\n",
    "\n",
    "        # Operators (AND/OR/XOR/IMPLIES/IFF)\n",
    "        if isinstance(node, Operator):\n",
    "            op = node.nodeType\n",
    "            vals = [self.eval(c) for c in node.children]\n",
    "            if op is LogicOperator.AND:     return self._and(vals)\n",
    "            if op is LogicOperator.OR:      return self._or(vals)\n",
    "            if op is LogicOperator.XOR:     return self._xor(vals)\n",
    "            if op is LogicOperator.IMPLIES: # reduce here just in case\n",
    "                if len(vals) != 2:\n",
    "                    return LogicTerminal.U\n",
    "                return self._or([self._not(vals[0]), vals[1]])\n",
    "            if op is LogicOperator.IFF:\n",
    "                if len(vals) != 2:\n",
    "                    return LogicTerminal.U\n",
    "                # (a↔b) := (a->b) ∧ (b->a)\n",
    "                ab = self._or([self._not(vals[0]), vals[1]])\n",
    "                ba = self._or([self._not(vals[1]), vals[0]])\n",
    "                return self._and([ab, ba])\n",
    "            raise ValueError(f\"Unsupported operator: {op}\")\n",
    "\n",
    "        # Quantifiers\n",
    "        if isinstance(node, QuantifierExpression):\n",
    "            return self._eval_quantifier(node)\n",
    "\n",
    "        # Fallback\n",
    "        raise ValueError(f\"Cannot evaluate node of type {type(node).__name__}\")\n",
    "\n",
    "    def _eval_variable(self, variable: Variable) -> LogicTerminal:\n",
    "        if variable.name in self.bindings:\n",
    "            bound = self.bindings[variable.name]\n",
    "            if isinstance(bound, bool):\n",
    "                return LogicTerminal.T if bound else LogicTerminal.F\n",
    "            if isinstance(bound, LogicTerminal):\n",
    "                return bound\n",
    "            return LogicTerminal.U\n",
    "        # Propositional variable lookup by name\n",
    "        return self.variable_environment.get(str(variable.name), LogicTerminal.U)\n",
    "\n",
    "    def _eval_predicate(self, predicate: Predicate) -> LogicTerminal:\n",
    "        # replace Variable by their bound values if present.\n",
    "        predicate_args: Tuple[Any, ...] = tuple(self.bindings.get(arg.name, arg) if isinstance(arg, Variable) else arg for arg in predicate.args)\n",
    "\n",
    "        # lookup in predicate table\n",
    "        key = (predicate.name, predicate_args)\n",
    "        if key in self.predicate_table:\n",
    "            return self.predicate_table[key]\n",
    "\n",
    "        # unknown if lookups do not yield truth value\n",
    "        return LogicTerminal.U\n",
    "\n",
    "    def _eval_quantifier(self, quantifier: QuantifierExpression) -> LogicTerminal:\n",
    "        # get domain\n",
    "        if isinstance(quantifier.domain, str):\n",
    "            domain_iterable = self._resolve_domain(quantifier.domain)\n",
    "        else:\n",
    "            domain_iterable = quantifier.domain\n",
    "\n",
    "        variables = list(quantifier.variables)\n",
    "        if not variables:\n",
    "            return self.eval(quantifier.expression)\n",
    "\n",
    "        # tries combinations of facts to find truth value\n",
    "        def assign_and_eval(arg_index: int) -> LogicTerminal:\n",
    "            if arg_index == len(variables):\n",
    "                return self.eval(quantifier.expression)  # all variables bound\n",
    "            variable = variables[arg_index]\n",
    "            result_accumulator: List[LogicTerminal] = []\n",
    "            for element in domain_iterable:\n",
    "                self.bindings[variable.name] = element\n",
    "                value = assign_and_eval(arg_index + 1) # Recurse and assign next value\n",
    "                result_accumulator.append(value)\n",
    "\n",
    "                if quantifier.quantifier is Quantifier.ALL and value is LogicTerminal.F:\n",
    "                    del self.bindings[variable.name]\n",
    "                    return LogicTerminal.F\n",
    "                if quantifier.quantifier is Quantifier.ANY and value is LogicTerminal.T:\n",
    "                    del self.bindings[variable.name]\n",
    "                    return LogicTerminal.T\n",
    "\n",
    "            # Clean binding for this variable\n",
    "            if variable.name in self.bindings:\n",
    "                del self.bindings[variable.name]\n",
    "\n",
    "            # Aggregate Unknowns\n",
    "            if quantifier.quantifier is Quantifier.ALL:\n",
    "                return self._and(result_accumulator)\n",
    "            else:\n",
    "                return self._or(result_accumulator)\n",
    "\n",
    "        return assign_and_eval(0)\n",
    "\n",
    "\n",
    "# </editor-fold>\n",
    "\n",
    "# <editor-fold desc=\"Wumpis World\">\n",
    "\n",
    "class Safety(Enum):\n",
    "    SAFE = auto()\n",
    "    RISKY = auto()\n",
    "    UNSAFE = auto()\n",
    "    UNKNOWN = auto()\n",
    "\n",
    "class PuzzleParser:\n",
    "    def __init__(self):\n",
    "        self.size: Tuple[int,int] = (-1, -1)\n",
    "        self.arrows: int = -1\n",
    "        self.path:Dict[Tuple:Dict[str:bool]] = {} # Relates Position to boolean values of Breeze and Stench\n",
    "        self.query:Tuple = (-1,-1)\n",
    "        self.resolution: Safety = Safety.UNKNOWN\n",
    "        self.file_read = False\n",
    "\n",
    "        try:\n",
    "            self.parse_puzzle()\n",
    "            self.file_read = True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filepath} not found\")\n",
    "            self.file_read = False\n",
    "        except Exception:\n",
    "            print(f\"Bad File: {filepath}\")\n",
    "            self.file_read = False\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.file_read\n",
    "\n",
    "    def parse_puzzle(self):\n",
    "        with open(filepath) as file:\n",
    "            path: List[str] = []\n",
    "            for raw in file.readlines():\n",
    "                line = raw.strip()\n",
    "                if line.startswith('GRID: '):\n",
    "                    grid = line.replace('GRID: ', '')\n",
    "                    self.size = tuple(map(int, grid.split('x')))\n",
    "                if line.startswith('ARROWS: '):\n",
    "                    self.arrows = int(line.replace('ARROWS: ', ''))\n",
    "                if line.startswith('QUERY: '):\n",
    "                    query = line.replace('QUERY: (', '')[:-1]\n",
    "                    self.query = tuple(map(int, query.split(',')))\n",
    "                if line.startswith('RESOLUTION: '):\n",
    "                    self.resolution = Safety[line.replace('RESOLUTION: ', '')]\n",
    "                if line.startswith('('):\n",
    "                    path.append(line)\n",
    "\n",
    "            for step in path:\n",
    "                position, breeze, stench = tuple(step[:-1].split(' '))\n",
    "                position = position[1:-1]\n",
    "                row, col = tuple(map(int, position.split(',')))\n",
    "                breeze = breeze[-1] == 'T'\n",
    "                stench = stench[-1] == 'T'\n",
    "                self.path[(row, col)] = {\"Breeze\": breeze, \"Stench\": stench}\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_path(self):\n",
    "        return self.path\n",
    "\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    def __init__(self):\n",
    "        # lowercase tuple in these definitions is a coordinate pair\n",
    "        self.rules: Optional[List[ParseNode]] = []\n",
    "        self.facts: Optional[Dict[Tuple[str,tuple]:LogicTerminal]] = {}\n",
    "        self.domains: Optional[Dict[str,List[tuple]]] = {}\n",
    "\n",
    "        self.puzzle = PuzzleParser()\n",
    "        if not self.puzzle: return\n",
    "\n",
    "        self.domains = {\n",
    "            'Cells':[]\n",
    "        }\n",
    "        for row in range(self.puzzle.size[0]):\n",
    "            for col in range(self.puzzle.size[1]):\n",
    "                self.domains['Cells'].append((row, col))\n",
    "\n",
    "        self.logic_parser = Parser()\n",
    "        self.rules.extend(map(self.logic_parser,[\n",
    "            \"ALL x IN Cells ( Wumpis(x) IMPLIES (NOT Safe(x)) )\",\n",
    "            \"ALL x IN Cells ( Pit(x) IMPLIES (NOT Safe(x)) )\",\n",
    "            \"ALL x IN Cells ( ((NOT Pit(x)) AND (NOT Wumpis(x))) IMPLIES Safe(x) )\",\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def get_neighbors(self,square: tuple)->List[Tuple[int,int]]:\n",
    "        neighbors: List[Tuple[int,int]] = []\n",
    "        xbounds,ybounds = zip((0,0),self.puzzle.get_size())\n",
    "\n",
    "        for diff in [(1,0),(-1,0),(0,1),(0,-1)]:\n",
    "            neighbor = (square[0] + diff[0], square[1] + diff[1])\n",
    "            if neighbor[0] < xbounds[0] or neighbor[0] >= xbounds[1]:\n",
    "                continue\n",
    "            if neighbor[1] < ybounds[0] or neighbor[1] >= ybounds[1]:\n",
    "                continue\n",
    "            neighbors.append(neighbor)\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "    def get_puzzle_facts(self):\n",
    "        path = self.puzzle.get_path()\n",
    "        for key in path:\n",
    "            self.facts[(\"Breeze\",tuple(key))] = LogicTerminal.T if path[key][\"Breeze\"] else LogicTerminal.F\n",
    "            self.facts[(\"Stench\",tuple(key))] = LogicTerminal.T if path[key][\"Stench\"] else LogicTerminal.F\n",
    "\n",
    "        for (name, (row, col)), value in self.facts.items():\n",
    "            if name == \"Stench\" and value == LogicTerminal.T:\n",
    "                self.rules.append(self.logic_parser(f\"ANY x IN neighbor{row}_{col} ( Wumpis(x))\"))\n",
    "                self.domains[f\"neighbor{row}_{col}\"]=self.get_neighbors((row,col))\n",
    "            elif name == \"Breeze\" and value == LogicTerminal.T:\n",
    "                self.rules.append(self.logic_parser(f\"ANY x IN neighbor{row}_{col} ( Pit(x)))\"))\n",
    "                self.domains[f\"neighbor{row}_{col}\"]=self.get_neighbors((row,col))\n",
    "\n",
    "\n",
    "\n",
    "class InferenceEngine:\n",
    "    # TODO: Write this class\n",
    "    def __init__(self):\n",
    "        self.knowledge = KnowledgeBase()\n",
    "\n",
    "    def get_knowledge_base(self):\n",
    "        return self.knowledge\n",
    "\n",
    "    def unify(self, a: Any, b: Any, theta: Optional[Dict[Any, Any]] = None) -> Optional[Dict[Any, Any]]:\n",
    "        \"\"\"\n",
    "        Try to unify two terms/literals/predicates.\n",
    "        Return a substitution dict if successful, else None.\n",
    "        \"\"\"\n",
    "        # TODO: implement Robinson unification (occurs check, recursive structure)\n",
    "        return None\n",
    "\n",
    "    def derive(self, max_iterations: int = 1000) -> int:\n",
    "        \"\"\"\n",
    "        Saturate the KB by forward-chaining: repeatedly apply rules to add new facts.\n",
    "        Returns number of new facts derived.\n",
    "        \"\"\"\n",
    "        # TODO: forward chaining / resolution\n",
    "        new_count = 0\n",
    "        return new_count\n",
    "\n",
    "    def classify(self, cell: Tuple[int, int]) -> Safety:\n",
    "        \"\"\"\n",
    "        Use the KB to classify a cell as SAFE/UNSAFE/RISKY/UNKNOWN.\n",
    "        \"\"\"\n",
    "        # TODO: encode domain-specific predicates, e.g., SAFE(r,c), PIT(r,c), WUMPUS(r,c)\n",
    "        return Safety.UNKNOWN\n",
    "\n",
    "class OutputWriter:\n",
    "    # TODO: Write this class\n",
    "    def __init__(self):\n",
    "        self.engine = InferenceEngine()\n",
    "        self.knowledge = self.engine.get_knowledge_base()\n",
    "\n",
    "    def write_result(self, kb: KnowledgeBase) -> None:\n",
    "        \"\"\"\n",
    "        Emit a final report describing how the puzzle was solved:\n",
    "        - metrics\n",
    "        - facts used\n",
    "        - (optionally) rules and/or proof traces\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# </editor-fold>\n",
    "\n",
    "lex = Lexer()\n",
    "parser = Parser()\n",
    "ast = parser.parse(lex.tokenize(\"ALL x IN D ( P(x) IMPLIES ( Q(x) AND NOT K(x) ) )\"))\n",
    "Parser.pretty_print(ast)\n",
    "\n",
    "domains = {\"D\": [1,2]}\n",
    "preds = {\n",
    "    (\"P\", (1,)): LogicTerminal.T,\n",
    "    (\"P\", (2,)): LogicTerminal.F,\n",
    "    (\"Q\", (1,)): LogicTerminal.F,\n",
    "    (\"Q\", (2,)): LogicTerminal.T,\n",
    "}\n",
    "print(ExpressionEvaluator(ast, predicate_table=preds, domains=domains).evaluation)  # -> True\n",
    "KnowledgeBase()\n"
   ],
   "id": "952df08cada322c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-- ALL x IN D\n",
      "    \\-- OR\n",
      "        | NOT\n",
      "        |   \\-- P(x)\n",
      "        \\-- AND\n",
      "            | Q(x)\n",
      "            \\-- NOT\n",
      "                \\-- K(x)\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.KnowledgeBase at 0x27544ff69f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
