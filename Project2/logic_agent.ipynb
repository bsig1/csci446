{
 "cells": [
  {
   "cell_type": "code",
   "id": "952df08cada322c9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-09T02:42:21.897019Z"
    }
   },
   "source": [
    "import fnmatch\n",
    "import time\n",
    "from pathlib import Path\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum, auto\n",
    "from typing import List, Union, Dict, Tuple, Optional, Any, TypeAlias, Iterable, Callable, FrozenSet\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "#Parameters\n",
    "filepath = \"Caves/easy/path_e1.txt\"\n",
    "\n",
    "# <editor-fold desc=\"Semantics and structure for FOL\">\n",
    "\n",
    "class TokenType(Enum):\n",
    "    XOR = auto()\n",
    "    OR = auto()\n",
    "    AND = auto()\n",
    "    NOT = auto()\n",
    "    ALL = auto()\n",
    "    ANY = auto()\n",
    "    IMPLIES = auto()\n",
    "    IFF = auto()\n",
    "    IN = auto()\n",
    "\n",
    "    TRUE = auto()\n",
    "    FALSE = auto()\n",
    "    IDENT = auto()\n",
    "\n",
    "    LPAREN = auto()\n",
    "    RPAREN = auto()\n",
    "    COMMA  = auto()\n",
    "\n",
    "    def __str__(self): return self.name\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Token:\n",
    "    type: TokenType\n",
    "    name: Optional[str] = None  # used for variables quantifiers and predicates\n",
    "\n",
    "class Lexer:\n",
    "    _whitespace = re.compile(r\"\\s+\")\n",
    "    _identifier = re.compile(r\"[A-Za-z_][A-Za-z0-9_]*\")\n",
    "\n",
    "    SYMBOLS = [\n",
    "        (\"(\", TokenType.LPAREN),\n",
    "        (\")\", TokenType.RPAREN),\n",
    "        (\",\", TokenType.COMMA),\n",
    "    ]\n",
    "\n",
    "    # keywords, case-sensitive\n",
    "    KEYWORDS = {\n",
    "        \"TRUE\": TokenType.TRUE,\n",
    "        \"FALSE\": TokenType.FALSE,\n",
    "\n",
    "        \"AND\": TokenType.AND,\n",
    "        \"OR\": TokenType.OR,\n",
    "        \"XOR\": TokenType.XOR,\n",
    "        \"NOT\": TokenType.NOT,\n",
    "\n",
    "        \"IMPLIES\": TokenType.IMPLIES,\n",
    "        \"IFF\": TokenType.IFF,\n",
    "\n",
    "        \"ALL\": TokenType.ALL,\n",
    "        \"ANY\": TokenType.ANY,\n",
    "        \"IN\": TokenType.IN,\n",
    "    }\n",
    "\n",
    "    def tokenize(self, text: str) -> List[Token]:\n",
    "        tokens: List[Token] = []\n",
    "        i = 0\n",
    "        length = len(text)\n",
    "\n",
    "        while i < length:\n",
    "            # skip whitespace\n",
    "            current = self._whitespace.match(text, i)\n",
    "            if current:\n",
    "                i = current.end()\n",
    "                if i >= length:\n",
    "                    break\n",
    "\n",
    "            matched_symbol = False\n",
    "            for symbol, token_type in self.SYMBOLS:\n",
    "                if text.startswith(symbol, i):\n",
    "                    tokens.append(Token(token_type))\n",
    "                    i += len(symbol)\n",
    "                    matched_symbol = True\n",
    "                    break\n",
    "            if matched_symbol:\n",
    "                continue\n",
    "\n",
    "            # Identifier / keyword\n",
    "            current = self._identifier.match(text, i)\n",
    "            if current:\n",
    "                lex = current.group(0)\n",
    "                i = current.end()\n",
    "\n",
    "                # Keyword\n",
    "                token_type = self.KEYWORDS.get(lex)\n",
    "                if token_type is not None:\n",
    "                    tokens.append(Token(token_type))\n",
    "                else:\n",
    "                    tokens.append(Token(TokenType.IDENT, name=lex))\n",
    "                continue\n",
    "\n",
    "            # fallback\n",
    "            raise ValueError(f\"Unexpected character at {i}: {repr(text[i])}\")\n",
    "\n",
    "        return tokens\n",
    "\n",
    "# Terms\n",
    "class LogicTerminal(Enum):\n",
    "    U = auto()  # Unknown\n",
    "    F = auto()  # False\n",
    "    T = auto()  # True\n",
    "\n",
    "    def __str__(self):\n",
    "        if self is LogicTerminal.U: return \"Unknown\"\n",
    "        if self is LogicTerminal.F: return \"False\"\n",
    "        if self is LogicTerminal.T: return \"True\"\n",
    "        return \"NULL\"\n",
    "\n",
    "    def __bool__(self): return self is LogicTerminal.T\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Variable:\n",
    "    name: Any\n",
    "    def __str__(self) -> str: return str(self.name)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Constant:\n",
    "    value: Any = LogicTerminal.U\n",
    "    def __str__(self) -> str: return str(self.value)\n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, Constant): return False\n",
    "        return self.value == other.value\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Predicate:\n",
    "    name: str\n",
    "    args: Tuple[Any, ...] = field(default_factory=tuple)  # must be immutable for hashing\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}({', '.join(map(str, self.args))})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Predicate): return False\n",
    "        return self.name == other.name and self.args == other.args\n",
    "\n",
    "\n",
    "class LogicOperator(Enum):\n",
    "    XOR = auto()\n",
    "    AND = auto()\n",
    "    OR = auto()\n",
    "    IFF = auto()\n",
    "    IMPLIES = auto()\n",
    "\n",
    "    def __str__(self): return self.name\n",
    "\n",
    "class Quantifier(Enum):\n",
    "    ANY = auto()\n",
    "    ALL = auto()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Not:\n",
    "    child: Any\n",
    "\n",
    "    def __str__(self): return \"Not \"+str(self.child)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Operator:\n",
    "    nodeType: LogicOperator\n",
    "    children: List[Any] = field(default_factory=list)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class QuantifierExpression:\n",
    "    quantifier: Quantifier\n",
    "    variables: Tuple[Variable, ...]\n",
    "    domain: Any\n",
    "    expression: 'Expression'\n",
    "\n",
    "SimpleTerm: TypeAlias = Union[Variable, Constant, LogicTerminal, None]\n",
    "Expression: TypeAlias = Union[Predicate, Not, Operator, QuantifierExpression, Constant, Variable]\n",
    "Term = Union[SimpleTerm, Expression]\n",
    "\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.expression: List[Token] = []\n",
    "        self.parse_index = 0\n",
    "\n",
    "    def __call__(self, arg: Union[str,List[Token]]):\n",
    "        if isinstance(arg, str):\n",
    "            lex = Lexer()\n",
    "            self.expression = lex.tokenize(arg)\n",
    "        elif isinstance(arg, list):\n",
    "            self.expression = arg\n",
    "        return self.parse(self.expression)\n",
    "\n",
    "    def parse(self, tokens: List[Token]) -> Term:\n",
    "        self.expression = tokens\n",
    "        self.parse_index = 0\n",
    "        return self.parse_expression()\n",
    "\n",
    "    def peek(self, k=0) -> Optional[Token]:\n",
    "        i = self.parse_index + k\n",
    "        return self.expression[i] if 0 <= i < len(self.expression) else None\n",
    "\n",
    "    def peek_is(self, t: TokenType) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if next token exists and is of a certain type\n",
    "        \"\"\"\n",
    "        tok = self.peek()\n",
    "        return tok is not None and tok.type is t\n",
    "\n",
    "    def eat(self) -> Optional[Token]:\n",
    "        tok = self.peek()\n",
    "        if tok is not None:\n",
    "            self.parse_index += 1\n",
    "        return tok\n",
    "\n",
    "    def expect(self, token_type: TokenType) -> Token:\n",
    "        tok = self.eat()\n",
    "        if tok is None or tok.type is not token_type:\n",
    "            raise ValueError(f\"Expected {token_type}, got {tok}\")\n",
    "        return tok\n",
    "\n",
    "    def parse_expression(self) -> Term:\n",
    "        node = self._parse_iff()\n",
    "        if self.peek() is not None:\n",
    "            raise ValueError(f\"Expression not empty after parsing\")\n",
    "        return node\n",
    "\n",
    "    def _parse_iff(self) -> Term:\n",
    "        node = self._parse_implies()\n",
    "        while self.peek_is(TokenType.IFF):\n",
    "            self.eat()\n",
    "            rhs = self._parse_implies()\n",
    "            node = self._reduce_iff(node, rhs)\n",
    "        return node\n",
    "\n",
    "    def _parse_implies(self) -> Term:\n",
    "        left = self._parse_xor()\n",
    "        if self.peek_is(TokenType.IMPLIES):\n",
    "            self.eat()\n",
    "            right = self._parse_implies()  # right-assoc\n",
    "            return self.reduce_implies(left, right)\n",
    "        return left\n",
    "\n",
    "    def _parse_xor(self) -> Term:\n",
    "        node = self._parse_or()\n",
    "        while self.peek_is(TokenType.XOR):\n",
    "            self.eat()\n",
    "            rhs = self._parse_or()\n",
    "            node = Operator(nodeType=LogicOperator.XOR, children=[node, rhs])\n",
    "        return node\n",
    "\n",
    "    def _parse_or(self) -> Term:\n",
    "        node = self._parse_and()\n",
    "        while self.peek_is(TokenType.OR):\n",
    "            self.eat()\n",
    "            rhs = self._parse_and()\n",
    "            node = Operator(nodeType=LogicOperator.OR, children=[node, rhs])\n",
    "        return node\n",
    "\n",
    "    def _parse_and(self) -> Term:\n",
    "        node = self._parse_not()\n",
    "        while self.peek_is(TokenType.AND):\n",
    "            self.eat()\n",
    "            rhs = self._parse_not()\n",
    "            node = Operator(nodeType=LogicOperator.AND, children=[node, rhs])\n",
    "        return node\n",
    "\n",
    "    def _parse_not(self) -> Term:\n",
    "        if self.peek_is(TokenType.NOT):\n",
    "            self.eat()\n",
    "            return Not(child=self._parse_not())\n",
    "        return self._parse_atom()\n",
    "\n",
    "    def _parse_atom(self) -> Term:\n",
    "        tok = self.peek()\n",
    "        if tok is None:\n",
    "            raise ValueError(\"Unexpected end of expression\")\n",
    "\n",
    "        # booleans\n",
    "        if tok.type is TokenType.TRUE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.T)\n",
    "        if tok.type is TokenType.FALSE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.F)\n",
    "\n",
    "        #'(' expr ')'\n",
    "        if tok.type is TokenType.LPAREN:\n",
    "            self.eat()\n",
    "            node = self._parse_iff()\n",
    "            self.expect(TokenType.RPAREN)\n",
    "            return node\n",
    "\n",
    "        # Quantifier (ALL/ANY)\n",
    "        if self.peek_is(TokenType.ALL) or self.peek_is(TokenType.ANY):\n",
    "            return self._parse_quantifier()\n",
    "\n",
    "        # Predicate or variable: IDENT [ '(' args ')' ]\n",
    "        if tok.type is TokenType.IDENT:\n",
    "            ident = self.eat()\n",
    "            name = ident.name\n",
    "\n",
    "            if self.peek_is(TokenType.LPAREN):\n",
    "                self.eat()\n",
    "                args: List[Term] = []\n",
    "                if not self.peek_is(TokenType.RPAREN):\n",
    "                    while True:\n",
    "                        args.append(self._parse_term())\n",
    "                        if self.peek_is(TokenType.COMMA):\n",
    "                            self.eat()\n",
    "                            continue\n",
    "                        break\n",
    "                self.expect(TokenType.RPAREN)\n",
    "                return Predicate(name=name, args=tuple(args))\n",
    "\n",
    "            # variable\n",
    "            return Variable(name=name)\n",
    "\n",
    "        raise ValueError(f\"Unexpected token in atom: {tok}\")\n",
    "\n",
    "    def _parse_term(self) -> Term:\n",
    "        tok = self.peek()\n",
    "        if tok is None:\n",
    "            raise ValueError(\"Unexpected end of arguments\")\n",
    "        if tok.type is TokenType.TRUE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.T)\n",
    "        if tok.type is TokenType.FALSE:\n",
    "            self.eat()\n",
    "            return Constant(LogicTerminal.F)\n",
    "        if tok.type is TokenType.IDENT:\n",
    "            return Variable(name=self.eat().name)\n",
    "        if tok.type is TokenType.LPAREN:\n",
    "            raise ValueError(\"Nested predicate arguments not supported\")\n",
    "        raise ValueError(f\"Invalid token: {tok}\")\n",
    "\n",
    "    def _parse_quantifier(self) -> Term:\n",
    "        quantifier_token = self.eat()\n",
    "        quantifier = Quantifier.ALL if quantifier_token.type is TokenType.ALL else Quantifier.ANY\n",
    "\n",
    "        # Variables: IDENT or '(' IDENT (',' IDENT)* ')'\n",
    "        variables: List[Variable] = []\n",
    "        if self.peek_is(TokenType.LPAREN):\n",
    "            self.eat()\n",
    "            while True:\n",
    "                ident = self.expect(TokenType.IDENT)\n",
    "                variables.append(Variable(name=ident.name))\n",
    "                if self.peek_is(TokenType.COMMA):\n",
    "                    self.eat()\n",
    "                    continue\n",
    "                break\n",
    "            self.expect(TokenType.RPAREN)\n",
    "        else:\n",
    "            ident = self.expect(TokenType.IDENT)\n",
    "            variables.append(Variable(name=ident.name))\n",
    "\n",
    "        # IN domain\n",
    "        self.expect(TokenType.IN)\n",
    "        domain_token = self.expect(TokenType.IDENT)\n",
    "        domain = domain_token.name\n",
    "\n",
    "        if self.peek_is(TokenType.LPAREN):\n",
    "            self.eat()\n",
    "            body = self._parse_iff()\n",
    "            self.expect(TokenType.RPAREN)\n",
    "        else:\n",
    "            body = self._parse_iff()\n",
    "\n",
    "        return QuantifierExpression(quantifier=quantifier, variables=tuple(variables), domain=domain, expression=body)\n",
    "\n",
    "    # Reductions for IMPLIES/IFF\n",
    "    @staticmethod\n",
    "    def reduce_implies(p: Term, q: Term) -> Term:\n",
    "        # p -> q  ==  (!p) OR q\n",
    "        return Operator(nodeType=LogicOperator.OR, children=[Not(p), q])\n",
    "\n",
    "    def _reduce_iff(self, p: Term, q: Term) -> Term:\n",
    "        # p <-> q  ==  (p -> q) AND (q -> p)\n",
    "        return Operator(\n",
    "            nodeType=LogicOperator.AND,\n",
    "            children=[self.reduce_implies(p, q), self.reduce_implies(q, p)]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def pretty_print(node: Term, indent: str = \"\", is_last: bool = True):\n",
    "        branch = \"\\\\-- \" if is_last else \"| \"\n",
    "        next_indent = indent + (\"    \" if is_last else \"|   \")\n",
    "\n",
    "        # Operator\n",
    "        if isinstance(node, Operator):\n",
    "            label = str(node.nodeType.name)\n",
    "            print(indent + branch + label)\n",
    "            for i, child in enumerate(node.children):\n",
    "                Parser.pretty_print(child, next_indent, i == len(node.children) - 1)\n",
    "            return\n",
    "\n",
    "        # NOT\n",
    "        if isinstance(node, Not):\n",
    "            print(indent + branch + \"NOT\")\n",
    "            Parser.pretty_print(node.child, next_indent, True)\n",
    "            return\n",
    "\n",
    "        # Predicate\n",
    "        if isinstance(node, Predicate):\n",
    "            print(indent + branch + str(node))\n",
    "            return\n",
    "\n",
    "        # Constant (LogicTerminal)\n",
    "        if isinstance(node, Constant):\n",
    "            print(indent + branch + str(node.value))\n",
    "            return\n",
    "\n",
    "        # Variable\n",
    "        if isinstance(node, Variable):\n",
    "            print(indent + branch + f\"Variable({node.name})\")\n",
    "            return\n",
    "\n",
    "        # Quantifier\n",
    "        if isinstance(node, QuantifierExpression):\n",
    "            quantifier_name = str(node.quantifier.name)\n",
    "            variables_str = \", \".join(v.name for v in node.variables)\n",
    "            domain_str = node.domain\n",
    "            label = f\"{quantifier_name} {variables_str} IN {domain_str}\"\n",
    "            print(indent + branch + label)\n",
    "            Parser.pretty_print(node.expression, next_indent, True)\n",
    "            return\n",
    "\n",
    "        # LogicTerminal\n",
    "        if isinstance(node, LogicTerminal):\n",
    "            print(indent + branch + str(node))\n",
    "            return\n",
    "\n",
    "        # Fallback\n",
    "        print(indent + branch + f\"{node}\")\n",
    "\n",
    "\n",
    "\n",
    "class ExpressionEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluate an AST\n",
    "    - For propositional variables: look up in variable_environment (by variable name)\n",
    "    - For predicates consult predicate_table\n",
    "    - For quantifiers need domains\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Term,\n",
    "        variable_environment: Optional[Dict[str, LogicTerminal]] = None,\n",
    "        predicate_table: Optional[Dict[Tuple[str, Tuple[Any, ...]], LogicTerminal]] = None,\n",
    "        domains: Optional[Dict[str, Union[Iterable,Callable]]] = None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.variable_environment = variable_environment or {}\n",
    "        self.predicate_table = predicate_table or {}\n",
    "        self.domains = domains or {}\n",
    "\n",
    "        # current variable bindings\n",
    "        self.bindings: Dict[str, Any] = {}\n",
    "\n",
    "        self.evaluation: LogicTerminal = self.eval(root)\n",
    "\n",
    "    def _resolve_domain(self, name: str) -> Iterable[Any]:\n",
    "        if name not in self.domains:\n",
    "            raise ValueError(f\"Domain '{name}' not provided.\")\n",
    "        domain = self.domains[name]\n",
    "        # If callable, pass current bindings so it can depend on bound vars\n",
    "        return domain(self.bindings) if callable(domain) else domain\n",
    "\n",
    "    @staticmethod\n",
    "    def implies(p: Term, q: Term) -> Term:\n",
    "        return Operator(LogicOperator.OR, [Not(p), q])\n",
    "\n",
    "    @staticmethod\n",
    "    def equivalence(p: Term, q: Term) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        Evaluate (p -> q) ∧ (q -> p).\n",
    "        \"\"\"\n",
    "        new_expression_tree = Operator(LogicOperator.AND, [ExpressionEvaluator.implies(p, q), ExpressionEvaluator.implies(q, p)])\n",
    "        return ExpressionEvaluator(new_expression_tree).evaluation\n",
    "\n",
    "    @staticmethod\n",
    "    def _not(arg: LogicTerminal) -> LogicTerminal:\n",
    "        match arg:\n",
    "            case LogicTerminal.F: return LogicTerminal.T\n",
    "            case LogicTerminal.T: return LogicTerminal.F\n",
    "            case _: return LogicTerminal.U\n",
    "\n",
    "    @staticmethod\n",
    "    def _and(args: List[LogicTerminal]) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        True IFF all entries are True. If at least one is false, false, if at least one is unknown, unknown\n",
    "        \"\"\"\n",
    "        if any(arg is LogicTerminal.F for arg in args): return LogicTerminal.F\n",
    "        if any(arg is LogicTerminal.U for arg in args): return LogicTerminal.U\n",
    "        return LogicTerminal.T\n",
    "\n",
    "    @staticmethod\n",
    "    def _or(args: List[LogicTerminal]) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        True IFF any entries are True. Then Unknown if any are unknown, false otherwise\n",
    "        \"\"\"\n",
    "        if any(arg is LogicTerminal.T for arg in args): return LogicTerminal.T\n",
    "        if any(arg is LogicTerminal.U for arg in args): return LogicTerminal.U\n",
    "        return LogicTerminal.F\n",
    "\n",
    "    @staticmethod\n",
    "    def _xor(args: List[LogicTerminal]) -> LogicTerminal:\n",
    "        \"\"\"\n",
    "        True if only one entry is true, with no unknown entries.\n",
    "        If the number of true args is <=1 then the evaluation can be unknown if unknown is present.\n",
    "        Otherwise false\n",
    "        \"\"\"\n",
    "        true_count = sum(int(bool(arg)) for arg in args)\n",
    "        if true_count > 1:\n",
    "            return LogicTerminal.F\n",
    "        if LogicTerminal.U in args:\n",
    "            return LogicTerminal.U\n",
    "        return LogicTerminal.T if true_count == 1 else LogicTerminal.F\n",
    "\n",
    "\n",
    "\n",
    "    def eval(self, node: Term) -> LogicTerminal:\n",
    "        # Constants / raw terminals\n",
    "        if isinstance(node, Constant): return node.value\n",
    "        if isinstance(node, LogicTerminal): return node\n",
    "\n",
    "        # Propositional variable alone\n",
    "        if isinstance(node, Variable):\n",
    "            return self._eval_variable(node)\n",
    "\n",
    "        # Predicates (possibly with vars)\n",
    "        if isinstance(node, Predicate):\n",
    "            return self._eval_predicate(node)\n",
    "\n",
    "        # Unary NOT\n",
    "        if isinstance(node, Not):\n",
    "            return self._not(self.eval(node.child))\n",
    "\n",
    "        # Operators (AND/OR/XOR/IMPLIES/IFF)\n",
    "        if isinstance(node, Operator):\n",
    "            op = node.nodeType\n",
    "            vals = [self.eval(c) for c in node.children]\n",
    "            if op is LogicOperator.AND:     return self._and(vals)\n",
    "            if op is LogicOperator.OR:      return self._or(vals)\n",
    "            if op is LogicOperator.XOR:     return self._xor(vals)\n",
    "            if op is LogicOperator.IMPLIES: # reduce here just in case\n",
    "                if len(vals) != 2:\n",
    "                    return LogicTerminal.U\n",
    "                return self._or([self._not(vals[0]), vals[1]])\n",
    "            if op is LogicOperator.IFF:\n",
    "                if len(vals) != 2:\n",
    "                    return LogicTerminal.U\n",
    "                # (a↔b) := (a->b) ∧ (b->a)\n",
    "                ab = self._or([self._not(vals[0]), vals[1]])\n",
    "                ba = self._or([self._not(vals[1]), vals[0]])\n",
    "                return self._and([ab, ba])\n",
    "            raise ValueError(f\"Unsupported operator: {op}\")\n",
    "\n",
    "        # Quantifiers\n",
    "        if isinstance(node, QuantifierExpression):\n",
    "            return self._eval_quantifier(node)\n",
    "\n",
    "        # Fallback\n",
    "        raise ValueError(f\"Cannot evaluate node of type {type(node).__name__}\")\n",
    "\n",
    "    def _eval_variable(self, variable: Variable) -> LogicTerminal:\n",
    "        if variable.name in self.bindings:\n",
    "            bound = self.bindings[variable.name]\n",
    "            if isinstance(bound, bool):\n",
    "                return LogicTerminal.T if bound else LogicTerminal.F\n",
    "            if isinstance(bound, LogicTerminal):\n",
    "                return bound\n",
    "            return LogicTerminal.U\n",
    "        # Propositional variable lookup by name\n",
    "        return self.variable_environment.get(str(variable.name), LogicTerminal.U)\n",
    "\n",
    "    def _eval_predicate(self, predicate: Predicate) -> LogicTerminal:\n",
    "        # replace Variable by their bound values if present.\n",
    "        predicate_args: Tuple[Any, ...] = tuple(self.bindings.get(arg.name, arg) if isinstance(arg, Variable) else arg for arg in predicate.args)\n",
    "\n",
    "        # lookup in predicate table\n",
    "        key = (predicate.name, predicate_args)\n",
    "        if key in self.predicate_table:\n",
    "            return self.predicate_table[key]\n",
    "\n",
    "        # unknown if lookups do not yield truth value\n",
    "        return LogicTerminal.U\n",
    "\n",
    "    def _eval_quantifier(self, quantifier: QuantifierExpression) -> LogicTerminal:\n",
    "        # get domain\n",
    "        if isinstance(quantifier.domain, str):\n",
    "            domain_iterable = self._resolve_domain(quantifier.domain)\n",
    "        else:\n",
    "            domain_iterable = quantifier.domain\n",
    "\n",
    "        variables = list(quantifier.variables)\n",
    "        if not variables:\n",
    "            return self.eval(quantifier.expression)\n",
    "\n",
    "        # tries combinations of facts to find truth value\n",
    "        def assign_and_eval(arg_index: int) -> LogicTerminal:\n",
    "            if arg_index == len(variables):\n",
    "                return self.eval(quantifier.expression)  # all variables bound\n",
    "            variable = variables[arg_index]\n",
    "            result_accumulator: List[LogicTerminal] = []\n",
    "            for element in domain_iterable:\n",
    "                self.bindings[variable.name] = element\n",
    "                value = assign_and_eval(arg_index + 1) # Recurse and assign next value\n",
    "                result_accumulator.append(value)\n",
    "\n",
    "                if quantifier.quantifier is Quantifier.ALL and value is LogicTerminal.F:\n",
    "                    del self.bindings[variable.name]\n",
    "                    return LogicTerminal.F\n",
    "                if quantifier.quantifier is Quantifier.ANY and value is LogicTerminal.T:\n",
    "                    del self.bindings[variable.name]\n",
    "                    return LogicTerminal.T\n",
    "\n",
    "            # Clean binding for this variable\n",
    "            if variable.name in self.bindings:\n",
    "                del self.bindings[variable.name]\n",
    "\n",
    "            # Aggregate Unknowns\n",
    "            if quantifier.quantifier is Quantifier.ALL:\n",
    "                return self._and(result_accumulator)\n",
    "            else:\n",
    "                return self._or(result_accumulator)\n",
    "\n",
    "        return assign_and_eval(0)\n",
    "\n",
    "\n",
    "# </editor-fold>\n",
    "\n",
    "from typing import Set\n",
    "\n",
    "\n",
    "# <editor-fold desc=\"Wumpis World\">\n",
    "class Safety(Enum):\n",
    "    SAFE = auto()\n",
    "    RISKY = auto()\n",
    "    UNSAFE = auto()\n",
    "    UNKNOWN = auto()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "class PuzzleParser:\n",
    "    def __init__(self):\n",
    "        self.size: Tuple[int,int] = (-1, -1)\n",
    "        self.arrows: int = -1\n",
    "        self.path: Dict[Tuple[int, int], Dict[str, bool]] = {} # Relates Position to boolean values of Breeze and Stench\n",
    "        self.query:Tuple = (-1,-1)\n",
    "        self.resolution: Safety = Safety.UNKNOWN\n",
    "        self.file_read = False\n",
    "\n",
    "        try:\n",
    "            self.parse_puzzle()\n",
    "            self.file_read = True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filepath} not found\")\n",
    "            self.file_read = False\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            print(f\"Bad File: {filepath}\")\n",
    "            self.file_read = False\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.file_read\n",
    "\n",
    "    def parse_puzzle(self):\n",
    "        with open(filepath) as file:\n",
    "            path: List[str] = []\n",
    "            for raw in file.readlines():\n",
    "                line = raw.strip()\n",
    "                if line.startswith('GRID: '):\n",
    "                    grid = line.replace('GRID: ', '')\n",
    "                    self.size = tuple(map(int, grid.split('x')))\n",
    "                if line.startswith('ARROWS: '):\n",
    "                    self.arrows = int(line.replace('ARROWS: ', ''))\n",
    "                if line.startswith('QUERY: '):\n",
    "                    query = line.replace('QUERY: (', '')[:-1]\n",
    "                    self.query = tuple(map(int, query.split(',')))\n",
    "                if line.startswith('RESOLUTION: '):\n",
    "                    self.resolution = Safety[line.replace('RESOLUTION: ', '')]\n",
    "                if line.startswith('('):\n",
    "                    path.append(line)\n",
    "\n",
    "            for step in path:\n",
    "                position, breeze, stench = tuple(step.split())\n",
    "                position = position[1:-1]\n",
    "                row, col = tuple(map(int, position.split(',')))\n",
    "                breeze = breeze[-1] == 'T'\n",
    "                stench = stench[-1] == 'T'\n",
    "                self.path[(row, col)] = {\"Breeze\": breeze, \"Stench\": stench}\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_path(self):\n",
    "        return self.path\n",
    "\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    def __init__(self):\n",
    "        self.rules: Set[FrozenSet[Term]] = set() # Each tuple is a set of disjuncts\n",
    "        self.facts: Set[FrozenSet[Term]] = set()\n",
    "\n",
    "        self.puzzle = PuzzleParser()\n",
    "        if not self.puzzle: return\n",
    "\n",
    "        self.logic_parser = Parser()\n",
    "\n",
    "        # Safe ⇒ ¬Pit and ¬Wumpus\n",
    "        self.add_rule(\"NOT Safe(x)\", \"NOT Pit(x)\")\n",
    "        self.add_rule(\"NOT Safe(x)\", \"NOT Wumpus(x)\")\n",
    "\n",
    "        # (¬Pit ∧ ¬Wumpus) ⇒ Safe  as one CNF clause:\n",
    "        self.add_rule(\"Safe(x)\", \"Pit(x)\", \"Wumpus(x)\")\n",
    "\n",
    "        self.get_puzzle_facts()\n",
    "\n",
    "    def __contains__(self, item: Tuple[Term]) -> bool:\n",
    "        clauses = self.facts | self.rules\n",
    "        if not isinstance(item, (set,tuple,list)):\n",
    "            return frozenset([item,]) in clauses\n",
    "        if isinstance(item, frozenset):\n",
    "            return item in clauses\n",
    "        return frozenset(item) in clauses\n",
    "\n",
    "    def add_rule(self,*rule):\n",
    "        \"\"\"\n",
    "        :param rule: accepts any number of arguments, these are taken as disjuncts to each other\n",
    "        \"\"\"\n",
    "        new_rule = []\n",
    "        for arg in rule:\n",
    "            if isinstance(arg, str):\n",
    "                new_rule.append(self.logic_parser(arg))\n",
    "            elif isinstance(arg, Term):\n",
    "                new_rule.append(arg)\n",
    "            elif isinstance(arg, (set,tuple,list,frozenset)):\n",
    "                new_rule.extend(list(arg))\n",
    "\n",
    "        self.rules.add(frozenset(new_rule))\n",
    "\n",
    "    def add_fact(self, *fact):\n",
    "        \"\"\"\n",
    "        :param fact: accepts any number of arguments, these are taken as disjuncts to each other\n",
    "        \"\"\"\n",
    "        new_fact = []\n",
    "        for arg in fact:\n",
    "            if isinstance(arg, str):\n",
    "                new_fact.append(self.logic_parser(arg))\n",
    "            elif isinstance(arg, Term):\n",
    "                new_fact.append(arg)\n",
    "            elif isinstance(arg, (set,tuple,list,frozenset)):\n",
    "                new_fact.extend(list(arg))\n",
    "\n",
    "        self.facts.add(frozenset(new_fact))\n",
    "\n",
    "\n",
    "    def get_neighbors(self,square: tuple)->List[Tuple[int,int]]:\n",
    "        neighbors: List[Tuple[int,int]] = []\n",
    "        xbounds,ybounds = zip((0,0),self.puzzle.get_size())\n",
    "\n",
    "        for diff in [(1,0),(-1,0),(0,1),(0,-1)]:\n",
    "            neighbor = (square[0] + diff[0], square[1] + diff[1])\n",
    "            if neighbor[0] < xbounds[0] or neighbor[0] >= xbounds[1]:\n",
    "                continue\n",
    "            if neighbor[1] < ybounds[0] or neighbor[1] >= ybounds[1]:\n",
    "                continue\n",
    "            neighbors.append(neighbor)\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "    def get_puzzle_facts(self):\n",
    "        path = self.puzzle.get_path()\n",
    "        for key in path:\n",
    "            self.add_fact(Predicate(\"Safe\",(Constant(value=key),)))\n",
    "            for sense in [\"Stench\", \"Breeze\"]:\n",
    "                fact = Predicate(sense, (Constant(value=key),))\n",
    "                if path[key][sense]:\n",
    "                    self.add_fact(fact)\n",
    "                else:\n",
    "                    self.add_fact(Not(fact))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InferenceEngine:\n",
    "    _fresh_id = 0\n",
    "    @classmethod\n",
    "    def _generate_symbol(self) -> int:\n",
    "        self._fresh_id += 1\n",
    "        return self._fresh_id\n",
    "\n",
    "    def __init__(self):\n",
    "        self._fresh_id = 0\n",
    "        self.kb = KnowledgeBase()\n",
    "        self.add_neighbor_info()\n",
    "        self.add_at_most_k_wumpus(self.kb.puzzle.arrows)\n",
    "        self.metrics = {\n",
    "            \"unifications\":0,\n",
    "            \"resolutions\":0\n",
    "        }\n",
    "        self.answer = self.query(self.kb.puzzle.query)\n",
    "\n",
    "        print(self.answer)\n",
    "\n",
    "    def add_neighbor_info(self):\n",
    "        hazards = {\"Stench\": \"Wumpus\", \"Breeze\": \"Pit\"}\n",
    "        new_disjuncts = []\n",
    "\n",
    "        for disjunct in self.kb.facts:\n",
    "            if len(disjunct) != 1:\n",
    "                continue\n",
    "\n",
    "            lit = next(iter(disjunct))\n",
    "            negated = isinstance(lit, Not)\n",
    "            fact = lit.child if negated else lit\n",
    "\n",
    "            if not isinstance(fact, Predicate):\n",
    "                continue\n",
    "            if fact.name not in hazards:\n",
    "                continue\n",
    "\n",
    "            cell = fact.args[0]\n",
    "            if not (isinstance(cell, Constant) and isinstance(cell.value, tuple)):\n",
    "                continue  # propagate only from ground cells\n",
    "\n",
    "            neighbors = self.kb.get_neighbors(cell.value)\n",
    "            hazard = hazards[fact.name]\n",
    "\n",
    "            if negated:\n",
    "                # not Sense(x) implies for all neighbors y: not Hazard(y)\n",
    "                for n in neighbors:\n",
    "                    new_disjuncts.append(Not(Predicate(hazard, (Constant(n),))))\n",
    "            else:\n",
    "                # Sense(x) implies at least one neighbor has Hazard\n",
    "                new_disjuncts.append(tuple(Predicate(hazard, (Constant(n),)) for n in neighbors))\n",
    "\n",
    "        for clause in new_disjuncts:\n",
    "            self.kb.add_fact(clause)\n",
    "\n",
    "    def _candidate_wumpus_cells(self) -> list[tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Cells that could still host a Wumpus given Stench facts:\n",
    "          - include neighbors of any Stench:T cell\n",
    "          - exclude neighbors of any Stench:F cell\n",
    "        \"\"\"\n",
    "        maybe: set[tuple[int, int]] = set()\n",
    "        ruled_out: set[tuple[int, int]] = set()\n",
    "\n",
    "        for clause in self.kb.facts:\n",
    "            if len(clause) != 1:\n",
    "                continue\n",
    "            lit = next(iter(clause))\n",
    "            is_neg = isinstance(lit, Not)\n",
    "            pred = lit.child if is_neg else lit\n",
    "            if not isinstance(pred, Predicate) or pred.name != \"Stench\":\n",
    "                continue\n",
    "\n",
    "            arg = pred.args[0]\n",
    "            if not (isinstance(arg, Constant) and isinstance(arg.value, tuple)):\n",
    "                continue\n",
    "\n",
    "            cell = arg.value\n",
    "            neigh = self.kb.get_neighbors(cell)\n",
    "            if is_neg:\n",
    "                ruled_out.update(neigh)\n",
    "            else:\n",
    "                maybe.update(neigh)\n",
    "\n",
    "        maybe.difference_update(ruled_out)\n",
    "        return sorted(maybe)\n",
    "\n",
    "    def add_at_most_k_wumpus(self, k: int):\n",
    "        domain = self._candidate_wumpus_cells()\n",
    "        if len(domain) <= k:\n",
    "            return\n",
    "        for group in combinations(domain, k + 1):\n",
    "            clause = [Not(Predicate(\"Wumpus\", (Constant(c),))) for c in group]\n",
    "            self.kb.add_rule(clause)\n",
    "\n",
    "    def occurs(self, variable: Variable, term: Term, theta: Dict[Term, Term]) -> bool:\n",
    "        term = self.substitute(term, theta)\n",
    "        if variable == term:\n",
    "            return True\n",
    "        if isinstance(term, Predicate):\n",
    "            return any(self.occurs(variable, a, theta) for a in term.args)\n",
    "        return False\n",
    "\n",
    "    def substitute(self, term: Term, theta: Dict[Term, Term]) -> Term:\n",
    "        if isinstance(term, Variable) and term in theta:\n",
    "            return self.substitute(theta[term], theta)\n",
    "        if isinstance(term, Constant):\n",
    "            return term\n",
    "        if isinstance(term, Not):\n",
    "            return Not(self.substitute(term.child, theta))\n",
    "        if isinstance(term, Predicate):\n",
    "            new_args = tuple(self.substitute(a, theta) for a in term.args)\n",
    "            return Predicate(term.name, new_args)\n",
    "        return term\n",
    "\n",
    "    def unify_var(self, variable: Term, term: Term, theta: Dict[Term, Term]) -> Optional[Dict[Term, Term]]:\n",
    "        term = self.substitute(term, theta)\n",
    "        if variable == term:\n",
    "            return theta\n",
    "        if self.occurs(variable, term, theta):\n",
    "            return None\n",
    "        theta[variable] = term\n",
    "        return theta\n",
    "\n",
    "    def unify(self, a: Term, b: Term, theta: Optional[Dict[Term, Term]] = None) -> Optional[Dict[Term, Term]]:\n",
    "        if theta is None:\n",
    "            theta = {}\n",
    "\n",
    "        self.metrics[\"unifications\"] += 1\n",
    "        a = self.substitute(a, theta)\n",
    "        b = self.substitute(b, theta)\n",
    "\n",
    "        if a == b:\n",
    "            return theta\n",
    "        if isinstance(a, Variable):\n",
    "            return self.unify_var(a, b, theta)\n",
    "        if isinstance(b, Variable):\n",
    "            return self.unify_var(b, a, theta)\n",
    "        if isinstance(a, Not) and isinstance(b, Not):\n",
    "            return self.unify(a.child, b.child, theta)\n",
    "        if isinstance(a, Predicate) and isinstance(b, Predicate):\n",
    "            if a.name != b.name or len(a.args) != len(b.args):\n",
    "                return None\n",
    "            for ai, bi in zip(a.args, b.args):\n",
    "                theta = self.unify(ai, bi, theta)\n",
    "                if theta is None:\n",
    "                    return None\n",
    "            return theta\n",
    "        if isinstance(a, Constant) and isinstance(b, Constant):\n",
    "            return theta if a == b else None\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def complements(a: Term, b: Term):\n",
    "        if isinstance(a, Not) and not isinstance(b, Not):\n",
    "            return b, a.child\n",
    "        if isinstance(b, Not) and not isinstance(a, Not):\n",
    "            return a, b.child\n",
    "        return None\n",
    "\n",
    "    def _standardize_apart(self, clause: frozenset) -> frozenset:\n",
    "        \"\"\"Rename all variables in a clause uniquely\"\"\"\n",
    "        vmap: Dict[Variable, Variable] = {}\n",
    "\n",
    "        def rename(term: Term) -> Term:\n",
    "            if isinstance(term, Variable):\n",
    "                if term not in vmap:\n",
    "                    vmap[term] = Variable(name=f\"{term.name}_{self._generate_symbol()}\")\n",
    "                return vmap[term]\n",
    "            if isinstance(term, Constant):\n",
    "                return Constant(term.value)\n",
    "            if isinstance(term, Not):\n",
    "                return Not(rename(term.child))\n",
    "            if isinstance(term, Predicate):\n",
    "                return Predicate(term.name, tuple(rename(a) for a in term.args))\n",
    "            return term\n",
    "\n",
    "        return frozenset(rename(lit) for lit in clause)\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_tautology(clause: frozenset) -> bool:\n",
    "        \"\"\"Detect L v not L inside the same clause.\"\"\"\n",
    "        seen = set()\n",
    "        for lit in clause:\n",
    "            key = (\"NOT\", lit.child) if isinstance(lit, Not) else (\"POS\", lit)\n",
    "            if key[0] == \"POS\" and (\"NOT\", key[1]) in seen:\n",
    "                return True\n",
    "            if key[0] == \"NOT\" and (\"POS\", key[1]) in seen:\n",
    "                return True\n",
    "            seen.add(key)\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def _subsumes(a: frozenset, b: frozenset) -> bool:\n",
    "        return a.issubset(b)\n",
    "\n",
    "    def resolve_clauses(self, clause1: frozenset, clause2: frozenset):\n",
    "        # Standardize apart to avoid variable collisions\n",
    "        clause1 = self._standardize_apart(clause1)\n",
    "        clause2 = self._standardize_apart(clause2)\n",
    "\n",
    "        resolvents = []\n",
    "        for L in clause1:\n",
    "            for R in clause2:\n",
    "                comps = self.complements(L, R)\n",
    "                if comps is None:\n",
    "                    continue\n",
    "                pos, neg = comps\n",
    "                theta = self.unify(pos, neg)\n",
    "                if theta is None:\n",
    "                    continue\n",
    "\n",
    "                self.metrics['resolutions'] += 1\n",
    "\n",
    "                # remove the resolved literals by identity, then substitute\n",
    "                merged = []\n",
    "                skip = {id(L), id(R)}\n",
    "                for t in list(clause1) + list(clause2):\n",
    "                    if id(t) in skip:\n",
    "                        continue\n",
    "                    merged.append(self.substitute(t, theta))\n",
    "\n",
    "                resolvent = frozenset(merged)\n",
    "                if not self._is_tautology(resolvent):\n",
    "                    resolvents.append(resolvent)\n",
    "        return resolvents\n",
    "\n",
    "    def resolution(self, *assumptions) -> bool:\n",
    "        clauses: set[frozenset] = set(self.kb.facts) | set(self.kb.rules)\n",
    "        for a in assumptions:\n",
    "            if isinstance(a, (list, tuple, set, frozenset)):\n",
    "                clauses.add(frozenset(a))\n",
    "            else:\n",
    "                clauses.add(frozenset((a,)))\n",
    "\n",
    "        while True:\n",
    "            new_resolutions: set[frozenset] = set()\n",
    "            clause_list = list(clauses)\n",
    "\n",
    "            clause_list.sort(key=len)\n",
    "            pruned: list[frozenset] = []\n",
    "            for clause in clause_list:\n",
    "                if any(self._subsumes(p, clause) for p in pruned):\n",
    "                    continue\n",
    "                pruned.append(clause)\n",
    "            clause_list = pruned\n",
    "\n",
    "            # Pairwise resolve\n",
    "            for i in range(len(clause_list)):\n",
    "                for j in range(i + 1, len(clause_list)):\n",
    "                    for res in self.resolve_clauses(clause_list[i], clause_list[j]):\n",
    "                        if len(res) == 0:\n",
    "                            return True  # derived empty clause\n",
    "                        if res not in clauses:\n",
    "                            new_resolutions.add(res)\n",
    "\n",
    "            if not new_resolutions:\n",
    "                return False\n",
    "            clauses |= new_resolutions\n",
    "\n",
    "    def print_resolutions(self, resolutions):\n",
    "        for resolution in resolutions:\n",
    "            for clause in resolution:\n",
    "                print(clause, end=' ')\n",
    "            print()\n",
    "\n",
    "    def query(self, cell: Tuple[int, int]) -> Safety:\n",
    "        safe = Predicate(\"Safe\", (Constant(cell),))\n",
    "        unsafe = Not(Predicate(\"Safe\", (Constant(cell),)))\n",
    "\n",
    "        if safe in self.kb:\n",
    "            return Safety.SAFE\n",
    "        if unsafe in self.kb:\n",
    "            return Safety.UNSAFE\n",
    "\n",
    "        if self.resolution(safe):   # KB ∧ Safe ⟹ ⊥ ⇒ KB ⊨ ¬Safe\n",
    "            return Safety.UNSAFE\n",
    "        if self.resolution(unsafe): # KB ∧ ¬Safe ⟹ ⊥ ⇒ KB ⊨ Safe\n",
    "            return Safety.SAFE\n",
    "        return Safety.RISKY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class OutputWriter:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        engine = InferenceEngine()\n",
    "\n",
    "\n",
    "        # Save to file immediately\n",
    "        self.write_result(engine)\n",
    "\n",
    "    def _format_clause(self, clause):\n",
    "        try:\n",
    "            if isinstance(clause, (list, tuple)):\n",
    "                return \" \".join(str(c) for c in clause if c)\n",
    "\n",
    "            return str(clause)\n",
    "        except Exception:\n",
    "            return str(clause)\n",
    "\n",
    "\n",
    "\n",
    "    def write_result(self, engine):\n",
    "        os.makedirs(\"Output\", exist_ok=True)\n",
    "\n",
    "        kb = engine.kb\n",
    "        base_name = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        output_file = os.path.join(\"Output\", f\"Group29_{base_name}_output.txt\")\n",
    "\n",
    "        # Metrics\n",
    "        metrics = getattr(engine, \"metrics\", {}) if engine else {}\n",
    "        num_facts = len(getattr(kb, \"facts\", []))\n",
    "        num_rules = len(getattr(kb, \"rules\", []))\n",
    "        query = engine.kb.puzzle.query\n",
    "        expected = str(engine.kb.puzzle.resolution)\n",
    "        result = str(engine.answer)\n",
    "\n",
    "\n",
    "\n",
    "        # Write the file\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"===== Wumpus World Logical Inference Report =====\\n\")\n",
    "            f.write(f\"Puzzle File: {filepath}\\n\\n\")\n",
    "\n",
    "            # METRICS\n",
    "            f.write(\"== METRICS ==\\n\")\n",
    "            f.write(f\"Facts in KB: {num_facts}\\n\")\n",
    "            f.write(f\"Rules in KB: {num_rules}\\n\")\n",
    "            f.write(f\"Resolutions: {metrics.get('resolutions', 'N/A')}\\n\")\n",
    "            f.write(f\"Unifications: {metrics.get('unifications', 'N/A')}\\n\\n\")\n",
    "\n",
    "            # FACTS\n",
    "            f.write(\"== FACTS USED ==\\n\")\n",
    "            for clause in getattr(kb, \"facts\", []):\n",
    "                f.write(f\"- {self._format_clause(tuple(clause))}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            # RULES\n",
    "            f.write(\"== RULES / CLAUSES ==\\n\")\n",
    "            for clause in getattr(kb, \"rules\", []):\n",
    "                f.write(f\"- {self._format_clause(tuple(clause))}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "            # FINAL QUERY RESULT\n",
    "            f.write(\"== FINAL QUERY RESULT ==\\n\")\n",
    "            f.write(f\"QUERY: {query}\\n\")\n",
    "            f.write(f\"Expected: {expected}\\n\")\n",
    "            f.write(f\"Result: {result}\\n\")\n",
    "\n",
    "        print(f\"[OutputWriter] Report automatically saved to {output_file}\")\n",
    "\n",
    "# </editor-fold>\n",
    "\n",
    "def test_all(root=None, levels=(\"easy\", \"medium\", \"hard\"), pattern=\".txt\", quiet=False):\n",
    "    # Base directory: .../Caves next to this file (unless overridden)\n",
    "    if root is None:\n",
    "        here = os.getcwd()\n",
    "\n",
    "        root = os.path.join(here, \"Caves\")\n",
    "\n",
    "    # Collect puzzle files (only *.txt), absolute + sorted for determinism\n",
    "    files = []\n",
    "    for level in levels:\n",
    "        level_dir = os.path.join(root, level)\n",
    "        if not os.path.isdir(level_dir):\n",
    "            if not quiet:\n",
    "                print(f\"[WARN] Missing directory: {level_dir}\")\n",
    "            continue\n",
    "        for dirpath, _, names in os.walk(level_dir):\n",
    "            for name in names:\n",
    "                if not name.lower().endswith(pattern):\n",
    "                    continue\n",
    "                files.append(os.path.abspath(os.path.join(dirpath, name)))\n",
    "    files.sort()\n",
    "\n",
    "    if not files:\n",
    "        print(\"[INFO] No puzzle files found.\")\n",
    "        return\n",
    "\n",
    "    # Run each file by setting the global `filepath` and calling OutputWriter()\n",
    "    ok, errs = 0, 0\n",
    "    t0 = time.perf_counter()\n",
    "    for i, path in enumerate(files, 1):\n",
    "        try:\n",
    "            if not quiet:\n",
    "                print(f\"[{i}/{len(files)}] {os.path.relpath(path, root)}\")\n",
    "            global filepath\n",
    "            filepath = path\n",
    "            OutputWriter()   # <-- no args, uses module-level `filepath`\n",
    "            ok += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {path}: {e}\")\n",
    "            errs += 1\n",
    "\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"\\nRan {len(files)} puzzles: {ok} ok, {errs} errors in {dt:.2f}s.\")\n",
    "\n",
    "\n",
    "test_all()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] easy\\path_e1.txt\n",
      "UNSAFE\n",
      "[OutputWriter] Report automatically saved to Output\\Group29_path_e1_output.txt\n",
      "[2/12] easy\\path_e2.txt\n",
      "RISKY\n",
      "[OutputWriter] Report automatically saved to Output\\Group29_path_e2_output.txt\n",
      "[3/12] easy\\path_e3.txt\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
