{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffeccb6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Transitions: 100%|██████████| 26136/26136 [00:02<00:00, 10077.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1 | Delta = 2.191600 | Progress: 0.00%\n",
      "Iter 2 | Delta = 1.740210 | Progress: 0.00%\n",
      "Iter 3 | Delta = 1.540239 | Progress: 0.00%\n",
      "Iter 4 | Delta = 1.332612 | Progress: 0.00%\n",
      "Iter 5 | Delta = 1.114457 | Progress: 0.00%\n",
      "Iter 6 | Delta = 0.908552 | Progress: 9.14%\n",
      "Iter 7 | Delta = 0.695975 | Progress: 30.40%\n",
      "Iter 8 | Delta = 0.485737 | Progress: 51.43%\n",
      "Iter 9 | Delta = 0.430467 | Progress: 56.95%\n",
      "Iter 10 | Delta = 0.387420 | Progress: 61.26%\n",
      "Iter 11 | Delta = 0.348678 | Progress: 65.13%\n",
      "Iter 12 | Delta = 0.313811 | Progress: 68.62%\n",
      "Iter 13 | Delta = 0.282430 | Progress: 71.76%\n",
      "Iter 14 | Delta = 0.254187 | Progress: 74.58%\n",
      "Iter 15 | Delta = 0.228768 | Progress: 77.12%\n",
      "Iter 16 | Delta = 0.205891 | Progress: 79.41%\n",
      "Iter 17 | Delta = 0.185302 | Progress: 81.47%\n",
      "Iter 18 | Delta = 0.166772 | Progress: 83.32%\n",
      "Iter 19 | Delta = 0.150095 | Progress: 84.99%\n",
      "Iter 20 | Delta = 0.135085 | Progress: 86.49%\n",
      "Iter 21 | Delta = 0.118192 | Progress: 88.18%\n",
      "Iter 22 | Delta = 0.055507 | Progress: 94.45%\n",
      "Iter 23 | Delta = 0.032146 | Progress: 96.79%\n",
      "Iter 24 | Delta = 0.016225 | Progress: 98.38%\n",
      "Iter 25 | Delta = 0.012385 | Progress: 98.76%\n",
      "Iter 26 | Delta = 0.009497 | Progress: 99.05%\n",
      "Iter 27 | Delta = 0.006562 | Progress: 99.34%\n",
      "Iter 28 | Delta = 0.004675 | Progress: 99.53%\n",
      "Iter 29 | Delta = 0.003068 | Progress: 99.69%\n",
      "Iter 30 | Delta = 0.001945 | Progress: 99.81%\n",
      "Iter 31 | Delta = 0.001199 | Progress: 99.88%\n",
      "Iter 32 | Delta = 0.000706 | Progress: 99.93%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAJdCAYAAADN8Fi6AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAN7tJREFUeJzt3QmYXGWZN+63sy8kgRDIAgkQtrAGTAQioFGWEJVNHMFBDcgfBJERQbkERxblPxlwvhFRhGFQGEZZZftERTFAWExAwAjIGrYQSEICJCEJWTpd3/Ue6KI73dVd3V1ddarOfV9XpU9Vnap6+5zurl/e5zmn6nK5XC4AANBCj5Y3AQAgKAEAtMGMEgBAAYISAEABghIAQAGCEgBAAYISAEABghIAQAGCEgBAAYISVMhxxx0Xtt5663bXe+WVV0JdXV245ppruv314+ucf/75Ic3uu+++ZJzxa5Z/LtIm7pNvfOMblR4GlJygBB308ssvJ28IO+ywQxgwYEBy2XnnncOpp54annjiiVRsz6VLl4Z+/folb17PPPNMyLJq2F/dKYau+HPQeNl8883D/vvvH2677bYOP9df/vKXJEjHny/Iil6VHgBUkzvvvDMcffTRoVevXuHYY48N48ePDz169AjPPvtsuPXWW8Pll1+evDFvtdVW7T7Xf//3f4eGhoZuGefNN9+cvCmOGDEi/PrXvw4XXnhhUY977733ku+tVpRyf1WzPfbYI5x55pnJ8htvvBH+67/+K3zuc59Lvv+TTz65Q0HpggsuSGa9Nt54424cMaRH7fxFhG724osvhmOOOSZ5U50xY0YYOXJks/svuuii8POf/zx5I27LypUrw8CBA0Pv3r27bay/+tWvwqc//elkrNddd13RQSnOQtWKUu+varbFFluEL33pS/nrX/nKV8J2220XfvzjH3coKEEWKb1BkS6++OLkTfPqq69u8aYbxVmLf/mXfwmjR4/O3xb/573RRhslb9oxuAwaNCiZ2SjUixJLGvH2IUOGJP9jnzZtWofLHPPmzQsPPPBAEhLiJc6YxJmAYrTWoxR7gSZOnJiEqG233TaZjYjrxHU3fGwscd1+++1h1113DX379g277LJLuOuuu1q8zuuvvx6++tWvhuHDh+fX++Uvf9livfnz54cjjjgiCSqxZPStb30rrFmzpiL7K87+XXLJJclY47aIY//a174W3nnnnRbP/Yc//CEpb8Vxx+f4zGc+E/7xj3+0WK9xW8Xni183LIflcrnkZ+Twww9v8djVq1cnPydxDB0VZxp32mmn5GcjiiXI+L2PHTs2GUu8P+6ft956K/+YuM+/853vJMvbbLNNvpQXe+ha+57a2v9QTcwoQQfKOPF/4XvvvXeHtll9fX2YMmVK2G+//cJ//Md/JD0yrYlvivEN8cEHH0z+lx/fyOIbZwxLHXH99dcnb9Cf/exnQ//+/ZNwE8tvH/vYx0JH/e1vfwuHHHJIEjRiyWX9+vXhBz/4Qdhss81aXT+OPZa0vv71rycB4dJLLw1HHXVUEt423XTTZJ1FixaFffbZJx+s4nPFYHHCCSeE5cuXh9NPPz1fBjzggAOSx8ZAM2rUqPC///u/4Z577qnI/oqBJDbUH3/88cl4Ysj42c9+lmyjhx56KD9DGMcY91l8jjhrtWrVqqTEFZ8vrtsYjv/0pz8l2yb2S02fPj0JJfG5t9xyy/xY4jaKM0Ex9L399tth6NCh+ft++9vfJtur6UxRsdatWxdee+21/D65++67w0svvZS8fgxJMdRdeeWVydfZs2cn44iluueffz75+YozUcOGDUse2/RnoZj9D1UnB7Rr2bJlufjrcsQRR7S475133sktXrw4f1m1alX+vmnTpiWP++53v9vicfG+rbbaKn/99ttvT9a9+OKL87fV19fn9t9//+T2q6++uqg9tdtuu+WOPfbY/PVzzjknN2zYsNy6devafP0ovs55552Xv37ooYfmBgwYkHv99dfzt73wwgu5Xr16Jetu+Ng+ffrk5s6dm7/t73//e3L7T3/60/xtJ5xwQm7kyJG5JUuWNHv8MccckxsyZEh++11yySXJY2+66ab8OitXrsxtt912ye333ntv2fbXAw88kNz+61//utntd911V7Pb33333dzGG2+cO/HEE5utt3DhwuR7a3r7HnvskWyHpUuX5m/705/+lDxf0/3y3HPPJbddfvnlzZ7zsMMOy2299da5hoaGXFvicx188MH57zfuk7it43OedtppyTpNt0Gj66+/Plnn/vvvz9/2ox/9KLnt5ZdfbrF+sfsfqo3SGxQh/s89imWZDU2ePDn5X3Xj5bLLLmuxzimnnNLua/z+979PykFN1+3Zs2c47bTTit5HsYTy5JNPhi9+8Yv52+LykiVLwh//+MfQEXH26M9//nNS+oqzOY3iLM3UqVNbfcyBBx6YzGA12n333cPgwYOT2Yoovp/ecsst4dBDD02W47gaL3EGZtmyZeHxxx/Pb484k/X5z38+/3xxduekk04q+/6KzfGxzHXQQQc1G/OECROS17j33nvzMzOxVNq4zRsvcT/Gma3G9RYsWBDmzJmTzDzF520Unz/OMDUVj9aLj42zgo3i7FKchYtlwQ1LoK2Js1eN329saI/fz5e//OVkxiuKM49NS3pxzHHWL2rcH8Vob/9DNVJ6gyLEMkK0YsWKFvfFnp133303KSm1VgaJ4adpOaWQV199NQkGG76577jjjs2ux5JUDBRNxXJJYxN3LLvFXpO5c+cmt8Wek1juiW+0sVemWG+++WbyWjEYbai126IxY8a0uG2TTTbJ9/EsXrw4CRKxrBMvhV63cXvE19kwCGy4Pcqxv1544YVkm8c+qbbGHNeLPvWpT7W6XgwNjd9btP3227dYJ35/G4aT2Hwdy5TxcbE5PQadWD6LYacYMWjFhv64LWPYjGXdpketxeAVS6s33HBD/ntptOHPWlva2/9QjQQlKEL8X38MMU899VSL+xp7YDZsam0Um1rbO7KqI2688cakl6SpODsTL7F/JDYwbzgrEcU3wBgcWptlKZU4c9Ka9ysz7zdERzGgFOq9irMQadtfcdwxJDWd1WmqsU+n8fuLfUqN4bWpzp56ITblx0b2+PrnnHNOEohjg30xoTGK/URxtqeQL3zhC0nDf2zWjqcSiD8j8XuJ/WkdOYVFe/sfqpGgBEWKszFXXXVVeOSRR8Jee+1V8u3WeBj7hmHmueeea7ZeLFHFEs+GZs6cmRwlFput44xBU/F/9LFkFY9IKrb5NwaDOBvVODPVVGu3FSMGijjbE8t6bb1xN26PGHTim2zTWaUNt0c59lcsJ8Uy5L777tusTNXaeo3brq3vr/G8TY0zUE219v3FJu74/cSgFMttsXk8HoFXCvFnI/7cxRmlc889N397a2MrpswHtUaPEhTprLPOSsoW8bDpWLYp9f+a4+Ho8YireIRUoxgofvrTnzZbL86UxDfhppemZbc4KxD7eppeTjzxxKTMU2hGpNDsQHzuGK7iSQqbhqTYH9MZ8TnjUVCxT6m12Z5Ymmu6PeLr/uY3v8nfFo8gK1Sy6879FWdc4r744Q9/2OK+uM8aT+EQQ2wsr/3bv/1bUhor9P3FfRhnbv7nf/6nWWkrBuCnn3661THEMlu8L+7fuB3jLFMpNM4Cbbg9WgtijeeTcmZussSMEhQpBo148sbYqBtLHo1neo5vMPFQ8XhfLNkU04/UmtjgHGcsvvvd7yZloVg+i4daF9MjEs8tFMNHbAYudNLIww47LPzkJz9JSnCFem02FM+dExuB47hig3MMC/GQ+HienNiM3Bn//u//njQ1xxJYDHDx+4w9MrEvJ87axOUo3hdfK/bnPPbYY0m4iCWtQqdX6M799YlPfCI5PUA8jD9+3wcffHByOoA46xL7heJ2jYE0hqQYdGOo+chHPpKEmTiLFg+P/93vfpdsx/g9RfG54ixRPG1ADHPx+46hOJ57qLXeqrhuPMQ+vl5spi92H7YnjvnjH/94cgqCGO7iySnjPm88x1JTsXk9+t73vpd8b3EbxJ/baj8hJ7Sp0ofdQbWJhz+fcsopyWHq/fr1y/Xv3z83bty43Mknn5ybM2dOs3Xj4eYDBw5s9XlaOzz/rbfeyn35y1/ODR48ODmcPC7/7W9/a/f0ALfcckuyzi9+8YuC69x3333JOj/5yU+KPj1ANGPGjNyee+6ZHPq97bbb5q666qrcmWeemXzvGz721FNPbfG68TXiazW1aNGiZN3Ro0fnevfunRsxYkTugAMOyF155ZXN1nv11VeTw+DjKQriKQ6++c1v5g/Jb+v0AN2xv6I4vgkTJiTPMWjQoORUDGeddVbujTfeaLZeHNuUKVOSfRhfM2634447Lvfoo4+22G877bRTrm/fvrmdd945d+utt7a6Xxp9/etfT7736667Lles+Fyf+cxn2lxn/vz5uSOPPDI5tUEc8z/90z8l31NrPw8//OEPc1tssUWuR48ezU4V0JH9D9WkLv7TdpQCaC6eMiCejLC1Pha6T2zo/sUvfhEWLlxY9Mwa0DV6lIA2xVMENBXDUTzHUTwfEeUTz28U+9Bij5eQBOWjRwloUzwnU+PngMXz+MQenD59+iTN0nS/2FMWe7diU3v8mJNvfvObNjuUkaAEtCmeSyeenymWe+I5hiZNmpQc1dXayRIpvXikW2xEj83b8bPT4tFyQPnoUQIAKECPEgBAAYISAEC19CjFzxWKZ+ONH3PgdPkAQKnFMyPFD8ceNWpUu5/FmbqgFEPS6NGjKz0MAKDGvfbaa+2enT91QSnOJEX7hU+HXqF3pYcDANSY+rAuPBh+n88cVRWUGsttMST1qhOUAIAS++AzSYpp8dHMDQBQgKAEAFCAoAQAUICgBABQgKAEAFCAoAQAUICgBABQgKAEAFCAoAQAUICgBABQgKAEAFCAoAQAUICgBABQgKAEAFCAoAQAUICgBABQgKAEAFCAoAQAUICgBABQQK9Cd0AlLTlpkh0AdJthV86ydSmKGSUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAnoVugOKteSkSTYWELL+d2vYlbNK/pxUnhklAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAgQlAIACBCUAgAIEJQCAAnoVuoPas+SkSZUeAkDN6q6/scOunNUtz0txzCgBABQgKAEAFCAoAQAUICgBABQgKAEAFCAoAQAUICgBABQgKAGF5XK2Tob1Wr++0kOAinPCSaCZvvXrwr7zngkHv/T3MGT1ynDKZ0+2hTKoR0ND+PWtPw7/2Hx0uGrPA8Mbgzet9JCgIgQloFk42v/Vp8OA+rX5rXL3teeH9T2yN/k89L0VoUeuITTU9Qhv998oZE2/+rVhyJr3wg5vLwhHPPtIuH3cXgITmSQoQUa1FY6aGvbeuyHLeubWh+Erl4UsqwshHPnsI+Gzzz8a7txhosBEpghKkCHFhKOlfQeEe7fZNXzkjZdCv/p1779LZlDWZ5SiulwuDFi3JvSvXxt65nKhd0ODwETmCEpQ4zoSju4eOz78ddT2ob5nz4qMlXTaaM174Z+fvD986cn7w6C1qwUmMkVQghokHFFKK/r2D1dOnBKu2+3jAhOZIyhBjRCO6G4CE1kkKEEVE46oBIGJLBGUoMoIR6SFwEQWCEpQBYQj0kxgopYJSpBSwhHVRmCiFglKkCLCEbVAYKKW1OVy6frUy+XLl4chQ4aEyeHw0Kuud8iqJSdNqvQQKBPhiKydh6nRuh49nOm7QoZdOStkWX1uXbgv3BGWLVsWBg8e3Oa6ZpSgAoQjssQME9VMUIIyEY7IOoGJaiQoQTcSjqAlgYlqIihBiQlHUByBiWogKEEJCEfQeQITaSYoQScJR1BaAhNVH5SmT58ebr311vDss8+G/v37h4997GPhoosuCjvuuGN+ndWrV4czzzwz3HDDDWHNmjVhypQp4ec//3kYPnx4d4wfyko4gu4nMFG151E65JBDwjHHHBM++tGPhvr6+nDOOeeEp556Kjz99NNh4MCByTqnnHJK+N3vfheuueaa5HxI3/jGN0KPHj3CQw89VNRrOI/S+5xHKT2EI6gs52EqPedRWlf0eZS6dMLJxYsXh8033zzMnDkzfPzjH09ecLPNNgvXXXdd+PznP5+sE2efdtpppzBr1qywzz77tPucgtL7BKXK2m3hK2Gf+c+HbZcuCvu/+nQYUL+2xTpL+w4I926za7h77Pjw11Hbh/qePSsyVsiKtgLTn7fZPTwxfKtww24fr+gYq4WgtK48J5yMLxANHTo0+frYY4+FdevWhQMPPDC/zrhx48KYMWMKBqVYnouXpkEJKumMv9yR/CGua+U+4QjSWZKb+uKccMiLc8IBLz0ZTjrslJCr62FXURKdDkoNDQ3h9NNPD/vuu2/Yddddk9sWLlwY+vTpEzbeeONm68b+pHhfob6nCy64oLPDgJIat3h+OOqZWc1CknAE6Q5MX51zT+i7vj75vZ2w8KVw2HN/DXeM27vSwyTrQenUU09N+pMefPDBLg3g7LPPDmeccUazGaXRo0d36TmhsyHpit9dEQbUr0uuL+m/Ufj/9/98eHDMzspqkObAtOv+4Wd/uCqMf/PVJCydO/Pm5H5hiVLo1NxkbNC+8847w7333hu23HLL/O0jRowIa9euDUuXLm22/qJFi5L7WtO3b9+kPtj0ApUKSUPWvJdcf3z41uHwY84O922zm5AEKbei34Bw3BGnhet32S+53iPkkrB0+LMPV3poZC0oxb7vGJJuu+22cM8994Rtttmm2f0TJkwIvXv3DjNmzMjf9txzz4V58+aFSZMmlW7U0J0hacQ24bRPnxhW9elnO0O1qKsLF+97RPjVB83cwhIVKb3Fcls8ou2OO+4IgwYNyvcdxdMAxPMqxa8nnHBCUkqLDd5xdui0005LQlIxR7xBKkLS1P9PSIJqVFcX/s+kw5LF2OjdGJYiZTjKEpQuv/zy5OvkyZOb3X711VeH4447Lln+8Y9/nJw36aijjmp2wklIGyEJapCwRCWDUjGnXOrXr1+47LLLkguklZAENUxYooScaILMEZIgO2FJzxJdJSiRKUISZIiwRAkISmSGkAQZJCzRRYISmSAkQYYJS3RBlz7rDaoxJD0ZNg3nL9w9DLjmb2FApQcHlOcDwjV400lmlMhcSPpe2C+8V9e70kMDys3MEp0gKJGpcpuQBBknLNFBghKZ6kkykwQIS3SEoETN0bgNtMvMEkUSlKgpQhJQNGGJIghK1AwhCegwYYl2CErUBCEJ6DRhiTYISlQ9IQnoMmGJAgQlqpqQBJSMsEQrBCWqlpAElJywxAYEJaqSkAR0G2GJJgQlqo6QBHQ7YYkPCEpUFSEJKBthCUGJaiIkAWUnLGWeGSWqgpAEVIywlGmCEqknJAEVJyxllqBEqglJQGoIS5kkKJFaQhKQOsJS5ghKpJKQBKSWsJQpghKpIyQBqScsZUZdLpfLhRRZvnx5GDJkSJgcDg+96nqHtFty0qRKD6GmQ9KTYdPwvbBfeK8KfhaA6lGyv925XDhz1v8NX3ry/uRqQ6gLP/jEP4U7xu0dsmjYlbNCNajPrQv3hTvCsmXLwuDBg9tc14wSqSEkAVXHzFLNE5RIBSEJqFrCUk0TlEhlT5JyG1BVhKWaJSiRysZtPUlA1RGWapKgRMU4ug2oOcJSzRGUqAghCahZwlJNEZQoOyEJqHnCUs0QlCgrIQnIDGGpJvSq9ADIjiOenh1Of+TOFo3bq/r0q/TQALo1LEXxpJQ9Qi6cO/PmMHj1qnDnjhPDO/0H2fIpZ0aJsjho7pxw3gM3C0lA9rQys3TGw3eGf73/N5UeGUUQlOh+uVw458Fb8lfnDxpqJgnIZFi6dce98jdNfuUfYZP33q3osGifoES32+7thWHjNauS5XU9eoavHPFN5TYge+rqwg8/8YWw+INyW5xZGvxBKwLpJSjR7U56/E/55csmTgnvDNjIVgeyqa4uXDt+cv7qQS/9vaLDoX2CEt1qu7cWhINeeiJZXjxgULjhgxo9QFb9eez4/PJBLwpKaScoUbbZpGvGfyqs6dXbFgcybeGgTcITm49Jlnd4e0HYaumblR4SbRCUKNts0i07T7K1AUIId2+7R347KL+lm6BEtzGbBNC6P2+ze35Z+S3dBCW6hdkkgMKU36qHoES3MJsE0Dblt+ogKFFyZpMA2qf8Vh0EJUrObBJA+5TfqkNmPhR3yUmOuOouw66clV/eOrcsHBTeP9LtrdAv3DerRxg2+8P7AdL2d6uS7zOx/Lb7m/PyR79d9ZGDQjVb0g3vtd2xrzrCjBIl9eXwdH75xrBjWFvX0xYGKED5Lf0EJUomziZ9PLyen036XRhr6wK0Qfkt/QQlSsZsEkDHOfot3QQlSsJsEkDnKL+lm6BESZhNAugc5bd0E5ToMrNJAF2j/JZeghJdZjYJoGuU39JLUKLLZ+F2pBtA1yi/pZegRMnOwu28SQCdp/yWToISJflMN+dNAuga5bd0EpToNLNJAKWj/JZOghKdYjYJoPSU39JHUKJTzCYBlJ7yW/oISnRpNmnxgEE+0w2gRJTf0kdQokuzSdeM/1RYW9fTVgQoEeW3dBGU6NJs0i07T7IFAUpI+S1dBCW6NJu0pldvWxCghJTf0kVQomhmkwDKQ/ktPQQlimY2CaA8lN/SQ1CiKGaTAMpH+S09BCWKYjYJoLyU39JBUKJdZpMAyk/5LR0EJdplNgmg/JTf0kFQok1mkwAqR/mt8gQl2mQ2CaBylN8qT1CiILNJAJWl/FZ5ghIFmU0CqDzlt8oSlGiV2SSAdFB+qyxBiVaZTQJIB+W3yhKUaGHi6y+Eg156IllePGBQuGXnSbYSQAUpv1WOoEQLF957fX75V7t9Iqzp1dtWAqgg5bfKEZRo5lMvPRGGr1yWLK8PdeH2cXvbQgAVpvxWOYISzRz57Oz88sytdwnL+w2whQBSQPmtMgQlmh3ptt9rzyXLb/cbEC74xNG2DkBKKL9VhqBEq0e6/WLPg8wmAaSI8ltlCEoknDcJIP2U38pPUCLhvEkA6af8Vn6CEmaTAKqE8lv5CUqYTQKoIspv5SUoZZzeJIDqovxWXoJSxulNAqguym/lJShlmNkkgOqk/FY+glKGmU0CqE7Kb+UjKGWU2SSA6qX8Vj6CUkaZTQKobspv5SEoZZDZJIDqp/xWHoJSBplNAqh+ym/lIShljNkkgNqh/Nb9BKWMMZsEUDuU31IYlO6///5w6KGHhlGjRoW6urpw++23N7v/uOOOS25vejnkkENKOWY6yWwSQG1RfkthUFq5cmUYP358uOyyywquE4PRggUL8pfrr7++q+OkBMwmAdQe5bfu1aujD5g6dWpyaUvfvn3DiBEjujIuSsxsEkDtlt/OnPV/k+UvPPVQuGrPA0Ooq6v0sGpGt/Qo3XfffWHzzTcPO+64YzjllFPCW2+9VXDdNWvWhOXLlze7UHpmkwBqt/y2rG//ZHmz994N+817utJDqiklD0qx7HbttdeGGTNmhIsuuijMnDkzmYFav359q+tPnz49DBkyJH8ZPXp0qYeUeWaTAGrb30aMzS9//ulZFR1LyHrprT3HHHNMfnm33XYLu+++e9h2222TWaYDDjigxfpnn312OOOMM/LX44ySsFRaZpMAattvdtonTH71H8lyQ50D2kup27fm2LFjw7Bhw8LcuXML9jMNHjy42YXSMZsEUPtmjR4X3u3TL1neY9ErIeRylR5Szej2oDR//vykR2nkyJHd/VK0wmwSQO1r6NEjPD7y/fLbJqtXhrHvLKr0kLIblFasWBHmzJmTXKKXX345WZ43b15y33e+850we/bs8MorryR9SocffnjYbrvtwpQpU7pj/LTBbBJAdjw6arv88sQ3Wq/iUIag9Oijj4Y999wzuUSxvygun3vuuaFnz57hiSeeCIcddljYYYcdwgknnBAmTJgQHnjggaTERnmZTQLIjkdHbptfnrjgxYqOJdPN3JMnTw65Nmqff/zjH7s6JkrAbBJAtjy/6aikT2nQ2tVh4hsvvt+n5HxKXaY1vkaZTQLIFn1K3UNQqkFmkwCySZ9S6QlKNchsEkA26VMqPUGpxphNAsiuxj6lKN+nRJcISjXGbBJAdulTKj1BqYaYTQJAn1JpCUo1xGwSAPqUSktQqhFmkwCI9CmVlqBUI8wmARDpUyotQakGmE0CoCl9SqUjKNUAs0kANKVPqXQEpSpnNgmADelTKh1BqYrV5RrC1x77U/76NeM/Fdb06l3RMQFQefqUSkdQqmJHPv1wOPDlJ5Lld/oNDLfsPKnSQwIgJfQplYagVMWO//s9+eX7x+xsNgmAPH1KpSEoVale9fVh2KrlyXL8JJ8f73NopYcEQIroUyoNQalKTVzwYui3vj5Z/uuo7cKy/gMrPSQAUkSfUmkISlXqoJf+nl++aZd9KzoWANJJn1LXCUpVqNf69eGTrzyZLK/q1Sc8NHpcpYcEQArpU+o6QakKTXxjbthk9apk+YGtdg6re/ep9JAASCF9Sl0nKFV52e3useMrOhYA0kufUtcJSlVG2Q2AjtCn1DWCUpVRdgOgI/QpdY2gVGWU3QDoCH1KXSMoVRFlNwA6Sp9S1whKVUTZDYDO0KfUeYJSFVF2A6Az9Cl1nqBUJZTdAOgsfUqdJyhVCWU3ADpLn1LnCUpVQtkNgK7Qp9Q5glIVUHYDoKv0KXWOoFQFlN0A6Cp9Sp0jKFUBZTcAukqfUucISimn7AZAqehT6jhBKeWU3QAoFX1KHScopZyyGwClok+p4wSlFFN2A6CU9Cl1nKCUYspuAJSaPqWOEZRSTNkNgFLTp9QxglJKKbsB0B30KXWMoJRSym4AdAd9Sh0jKKWUshsA3UWfUvEEpRRSdgOgO+lTKp6glELKbgB0J31KxROUUkjZDYDupE+peIJSyii7AVAO+pSKIyiljLIbAOWgT6k4glLKKLsBUA76lIojKKWIshsA5aJPqTiCUooouwFQTvqU2icopYiyGwDlpE+pfYJSSii7AVBu+pTaJyilhLIbAOWmT6l9glJKKLsBUAn6lNomKKWAshsAlaJPqW2CUgoouwFQKfqU2iYopYCyGwCVok+pbYJShSm7AVBp+pQKE5QqTNkNgErTp1SYoFRhym4AVJo+pcIEpQpSdgMgDfQpFSYoVZCyGwBpoU+pdYJSBSm7AZAW+pRaJyhViLIbAGmiT6l1glKFKLsBkCb6lFonKFWIshsAaaNPqSVBqQKU3QBII31KLQlKFaDsBkAa6VNqSVCqAGU3ANJIn1JLglKZKbsBkGb6lJoTlMpM2Q2ANNOn1JygVGbKbgCkmT6l5gSlMlJ2AyDt9Ck1JyiVkbIbANVAn9KHBKUyUnYDoBroU/qQoFQmym4AVAt9Sh8SlMpE2Q2AaqFP6UOCUpl84R8P5ZfvHju+XC8LAJ2iT+l9glIZ9F23Jkx+9R/Jcn1dj/DQ6HHleFkAKEmf0ql/vSuzW1JQKoOjnpkd6j5YXjRwSFjdu085XhYAutSn1PDB8kZrV4eQy2VyawpKZTB8xdL88kNjdirHSwJAl/uU1vbsnSyv6t0n9F1fn8ktKiiVwfbvLMwv/3rX/cvxkgDQZcv6DUi+ruzTL6zp9X5oyhpBqZv1Wl8f9lj4SrK8cOCQMG/jzbr7JQGAEhGUutkui18L/evXfngEQV1jtxIAkHaCUjeb8MaL+eXHRn14BAEAkH6CUjebuODFVg+1BADST1AqY3/S/MGbdufLAQAlJih1I/1JAFDdBKVupD8JAKqboNSN9CcBQHUTlLqJ/iQAqH6CUjfRnwQA1U9Q6ib6kwCg+glK3UR/EgBUP0GpG+hPAoDaICh1A/1JAJDRoHT//feHQw89NIwaNSrU1dWF22+/vdn9uVwunHvuuWHkyJGhf//+4cADDwwvvPBCyBL9SQCQ0aC0cuXKMH78+HDZZZe1ev/FF18cLr300nDFFVeEhx9+OAwcODBMmTIlrF69OmSF/iQAqA29OvqAqVOnJpfWxNmkSy65JPzrv/5rOPzww5Pbrr322jB8+PBk5umYY44JtU5/EgDUjpL2KL388sth4cKFSbmt0ZAhQ8Lee+8dZs2aFbJAfxIAZHhGqS0xJEVxBqmpeL3xvg2tWbMmuTRavnx5qGb6kwCgdlT8qLfp06cns06Nl9GjR4dqpj8JAGpHSYPSiBEjkq+LFi1qdnu83njfhs4+++ywbNmy/OW1114L1Up/EgDUlpIGpW222SYJRDNmzGhWSotHv02aNKnVx/Tt2zcMHjy42aVa6U8CgIz3KK1YsSLMnTu3WQP3nDlzwtChQ8OYMWPC6aefHi688MKw/fbbJ8Hp+9//fnLOpSOOOCLUOv1JAJDxoPToo4+GT37yk/nrZ5xxRvJ12rRp4ZprrglnnXVWcq6lk046KSxdujTst99+4a677gr9+vULtU5/EgBkPChNnjw5OV9SIfFs3T/4wQ+SS5boTwKA2lPxo95qhf4kAKg9glKJ6E8CgNojKJWI/iQAqD2CUgnoTwKA2iQolYD+JACoTYJSCehPAoDaJCiVgP4kAKhNglIX6U8CgNolKHWR/iQAqF2CUhfpTwKA2iUodZH+JACoXYJSF+hPAoDaJih1gf4kAKhtglIX6E8CgNomKHWB/iQAqG2CUifpTwKA2icodZL+JACofYJSJ+lPAoDaJyh1kv4kAKh9glIn6E8CgGwQlDpBfxIAZIOg1An6kwAgGwSlTtCfBADZICh1kP4kAMgOQamD9CcBQHYISh2kPwkAskNQ6iD9SQCQHYJSB+hPAoBsEZQ6QH8SAGSLoNQB+pMAIFsEpQ7QnwQA2SIoFUl/EgBkj6BUJP1JAJA9glKR9CcBQPYISkXSnwQA2SMoFUF/EgBkk6BUBP1JAJBNglIR9CcBQDYJSkXQnwQA2SQotUN/EgBkl6DUDv1JAJBdglI79CcBQHYJSu3QnwQA2SUotUF/EgBkm6DUBv1JAJBtglIb9CcBQLYJSm3QnwQA2SYoFaA/CQAQlArQnwQACEoF6E8CAASlAvQnAQCCUiv0JwEAkaDUCv1JAICgVID+JABAUCpAfxIAICi1Qn8SANBIj9IG9CcBAI0EpQ3oTwIAGglKbfQn/fMT9294NwCQIYLSBlb06RcaPlgevGZV+fcIAJAagtIGzjpoWlg8YPD7V+rqKrBLAIC0EJRaIyABAIISAEBhZpQAAAoQlAAAChCUAAAKEJQAAAoQlAAAChCUAAAKEJQAAAoQlAAAChCUAAAKEJQAAAoQlAAAChCUAAAKEJQAAAoQlAAAChCUAAAKEJQAgFb1rV+XfK3LNWR2CwlKAECrNlq7Ovm62ap3Q6/16zO5lQQlAKCFAWtXh54fzCTV9+gZ6nv2zORWEpQAgBbGLXk91H2w/G6ffpndQoISANDCzkvm55d/ttenM7uFBCUAoIWdFr+WX356sy0zu4UEJQCghZ0+mFFa26NneHGTEZndQoISANCikXurpUuS5ec3HRXqe/bK7BYSlACAFo3cPUIuWX4mw2W3SFACAAo2cj8zTFACAMjTyP0hM0oAQDMauT8kKAEAeRq5mxOUAIA8jdzNCUoAQJ5G7uYEJQAgTyN3c4ISAJCnkbs5QQkASGjkbklQAgASGrnLEJTOP//8UFdX1+wybty4Ur8MAFBiGrlb6pZPudtll13Cn//85w9fpFd2P0wPAKqFRu6WuiXBxGA0YsSI7nhqAKCbaOQuU4/SCy+8EEaNGhXGjh0bjj322DBv3rzueBkAoEQ0cpdpRmnvvfcO11xzTdhxxx3DggULwgUXXBD233//8NRTT4VBgwa1WH/NmjXJpdHy5ctLPSQAoB0aucsUlKZOnZpf3n333ZPgtNVWW4WbbropnHDCCS3Wnz59ehKmAIDK0chdodMDbLzxxmGHHXYIc+fObfX+s88+Oyxbtix/ee2117p7SADABjRyVygorVixIrz44oth5MiRrd7ft2/fMHjw4GYXAKC8NHKXKSh9+9vfDjNnzgyvvPJK+Mtf/hKOPPLI0LNnz/DFL36x1C8FAJSARu4y9ijNnz8/CUVvvfVW2GyzzcJ+++0XZs+enSwDAOmjkbuMQemGG24o9VMCAN1II3dhPusNADJOI3dhghIAZJxG7sIEJQDIMI3cbROUACDDNHK3TVACgAzTyN02QQkAMkwjd9sEJQDIMI3cbROUACCjNHK3T1ACgIzSyN0+QQkAMkojd/sEJQDIKI3c7ROUACCjNHK3T1ACgAzSyF0cQQkAMkgjd3EEpVYMfW9Fs68AUGs0chdHUGpto+Qamn0FgFqjkbs4glIrGup6NPsKALVGI3dxJIFWvN1/o2ZfAaCWaOQunqAEABmjkbt4ghIAZIxG7uIJSgCQMRq5iycoAUDGaOQunqAEABmikbtjBCUAyBCN3B0jKAFAhmjk7hhBCQAyRCN3xwhKAJAhGrk7RlACgIzQyN1xghIAZIRG7o4TlAAgIzRyd5ygBAAZoZG74wQlAMgIjdwdJygBQAZo5O4cQQkAMkAjd+cISgCQARq5O0dQAoAM0MjdOYISAGSARu7OEZQAoMZp5O48QQkAapxG7s4TlACgxmnk7jxBCQBqnEbuzhOUAKDGaeTuPEEJAGqYRu6uEZQAoIZp5O4aQQkAaphG7q4RlACghmnk7hpBCQBqmEburhGUAKBGaeTuOkEJAGqURu6uE5QAoEZp5O46QQkAapRG7q4TlACgRmnk7jpBCQBqkEbu0hCUAKAGaeQuDUEJAGqQRu7SEJQAoAZp5C4NQQkAapBG7tIQlFox9L0Vzb4CQDXRyF06glJrGyXX0OwrAFQTjdylIyi1oqGuR7OvAFBNNHKXjiTQirf7b9TsKwBUE43cpSMoAUCN0chdOoISANQQjdylJSgBQA3RyF1aghIA1BCN3KUlKAFADdHIXVqCEgDUEI3cpSUoAUCN0MhdeoISANQIjdyl1ytkRO8jFhe/8m8aQlgZQujX0LHHZdWVlR4AQOU9dv7llR5CCFe8E8Jv31886qtzw1HHpmBMXTTlyj1CJZlRAoAaUffEmg+v7N6vkkOpGYISANSKD4JSrk8IYcf4D10lKAFALVjREMJL695f3rlvCH3qKj2imiAobWDdupWhoeH9H7T4NV4HgDRbtHjTcM8Ve4a63PvXV20/pNJDqhmC0gdWrXozvPjCHWHO4z8L6+tXJ7fFr/F6vD3eDwBp8uQzO4R/Pvk/w5g9Hwy//z8fy99+xm9+kNwe76drBKUQwrKlL4Wnn/qf8Pbbz8bK7gabKJfcHu+P6wFAGvzx3v3CPlNvDbfcOTXUr+8VJoTH8vc9ktsruT3eH9ej8zIflOJM0QvP3xJyufWthKRGueT+uJ6ZJQAqLc4Ufe74K8Katb2TkBQ1BqU1oU/4R9gluT3eH9czs9R5mQ9KC16fFXK5hqI2VlxvwRuzurC5AaDrpv/k5FBf3zPkcu+/jW8U3g07hOeT5b+H8WFdeP+It3h/XO/fLz3ZZu+kTAel2KjdermtkFx4+61nNXgDUNHG7cZyW6M9w99Cjw/eyx4LE5qtH9f7zW+nhjeXDC37WGtBpoPS8uXzOhCSGuXCu8njAKD87vvL3s1CUjQxPJpf3jAoRXH9+Dg6LtNBqWH92k49bn0nHwcAXfXuioEtbmvayN1aUIqWv7uRjd8Jmfmst9b06Nn6WUsXbtT864Z6FngcAHS3QRu1PL/fN8NPwrXhK0lgio3crRk8aIWd0wmZDkqDB4+Jn4zTovz20a+19ai6MCh5HACU3+SPPRx69axvVn57KwwLfwpTkktr4vrxcXRcpktvvXsPDEOHjvsgLBWjLgzddFzyOACohOGbvRWO+uwfkvBTjLje5w/9Q9h82NvdPrZalOmgFI3cYlKoqytuM8T1Ro6a1O1jAoC2nP3NK0KvXutDXV3bp7eJ9/fqVR+++y9X2KCdlPmgNGDA5mH7HY4KdXU925hZqkvuj+vF9QGgknbb6flw69Unh7591hWcWYq39+2zNtx69SnJ+nRO5oNSNGTjsWHnXaclZbWWYen9clu8P64HAGkw5ZMPhtl/+FxSVtswLDWW22b/4ahkPTqvLpfLdfREQt1q+fLlYciQIWFyODz0qutdsudd9vvtij4JZTxPUjwFQDy6LTZu60lq25BPzy3JPgKoZn98Y07FXjueTDKeJymeAiAe3RYbt2ulJ2nKqD1K/pz1uXXhvnBHWLZsWRg8eHCb62b6qLeCDd6b7lTpYQBA0WIo+sJhf7DFuoHSGwBA1meUlIcAqLYSEZVnRgkAoABBCQCgAEEJAKAAQQkAoABBCQCgAEEJAKDcQemyyy4LW2+9dejXr1/Ye++9wyOPPNJdLwUAUD1B6cYbbwxnnHFGOO+888Ljjz8exo8fH6ZMmRLefPPN7ng5AIDqCUr/+Z//GU488cRw/PHHh5133jlcccUVYcCAAeGXv/xld7wcAEB1BKW1a9eGxx57LBx44IEfvkiPHsn1WbNmtVh/zZo1yQfhNr0AANRkUFqyZElYv359GD58eLPb4/WFCxe2WH/69OlhyJAh+cvo0aNLPSQAgOo86u3ss88Oy5Yty19ee+21Sg8JAKB7PhR32LBhoWfPnmHRokXNbo/XR4wY0WL9vn37JhcAgJqfUerTp0+YMGFCmDFjRv62hoaG5PqkSZNK/XIAANUzoxTFUwNMmzYtTJw4Mey1117hkksuCStXrkyOggMAyHRQOvroo8PixYvDueeemzRw77HHHuGuu+5q0eANAJBmdblcLhdSJJ4eIB79NjkcHnrV9a70cACAGlOfWxfuC3ckB5ENHjw43Ue9AQCklaAEAFCAoAQAUM5m7q5obJmqD+tCSFX3FABQC5KM0SRzVFVQevfdd5OvD4bfV3ooAEANi5kjHkBWVUe9xZNTvvHGG2HQoEGhrq6u3SPk4mfDxY89aa9rncqzv6qL/VVd7K/qYV9VXow+MSSNGjUq9OjRo7pmlOKAt9xyyw49JoYkQal62F/Vxf6qLvZX9bCvKqu9maRGmrkBAAoQlAAAajEo9e3bN5x33nnJV9LP/qou9ld1sb+qh31VXVLXzA0AkBZVPaMEANCdBCUAgAIEJQCAAgQlAIBaDEqXXXZZ2HrrrUO/fv3C3nvvHR555JFKD4lWnH/++clZ1ptexo0bZ1ulwP333x8OPfTQ5Oy0cb/cfvvtze6Px3qce+65YeTIkaF///7hwAMPDC+88ELFxpt17e2v4447rsXv2iGHHFKx8Wbd9OnTw0c/+tHkkyY233zzcMQRR4Tnnnuu2TqrV68Op556ath0003DRhttFI466qiwaNGiio2ZGgpKN954YzjjjDOS0wM8/vjjYfz48WHKlCnhzTffrPTQaMUuu+wSFixYkL88+OCDtlMKrFy5Mvndif/paM3FF18cLr300nDFFVeEhx9+OAwcODD5PYt/3Enf/opiMGr6u3b99deXdYx8aObMmUkImj17drj77rvDunXrwsEHH5zsx0bf+ta3wm9/+9tw8803J+vHj/D63Oc+ZzOmSa5K7bXXXrlTTz01f339+vW5UaNG5aZPn17RcdHSeeedlxs/frxNk3Lxz8Ftt92Wv97Q0JAbMWJE7kc/+lH+tqVLl+b69u2bu/766ys0Sgrtr2jatGm5ww8/3EZKqTfffDPZbzNnzsz/PvXu3Tt3880359d55plnknVmzZpVwZHSVFXOKK1duzY89thjSRmg6WfExeuzZs2q6NhoXSzXxHLB2LFjw7HHHhvmzZtnU6Xcyy+/HBYuXNjs9yx+NlIsc/s9S6/77rsvKfPsuOOO4ZRTTglvvfVWpYfEB5YtW5Z8HTp0aPI1vo/FWaamv2OxLWHMmDF+x1KkKoPSkiVLwvr168Pw4cOb3R6vxz/spEt8Y73mmmvCXXfdFS6//PLkDXj//fdPPrmZ9Gr8XfJ7Vj1i2e3aa68NM2bMCBdddFFSypk6dWry95LKamhoCKeffnrYd999w6677pr/HevTp0/YeOONm63rvSxdelV6ANS++Ie60e67754Ep6222ircdNNN4YQTTqjo2KCWHHPMMfnl3XbbLfl923bbbZNZpgMOOKCiY8u62Kv01FNP6c+sQlU5ozRs2LDQs2fPFkcGxOsjRoyo2LgoTvzf0w477BDmzp1rk6VY4++S37PqFUvd8e+l37XK+sY3vhHuvPPOcO+994Ytt9yy2e9YbCVZunRps/W9l6VLVQalOFU5YcKEZHq56bRmvD5p0qSKjo32rVixIrz44ovJIeek1zbbbJP8IW/6e7Z8+fLk6De/Z9Vh/vz5SY+S37XKiD33MSTddttt4Z577kl+p5qK72O9e/du9jsWTx8Qezj9jqVH1Zbe4qkBpk2bFiZOnBj22muvcMkllySHXB5//PGVHhob+Pa3v52c+yWW2+Khr/GUDnFG8Itf/KJtlYLQ2nS2IfaPzZkzJ2k2jQ2lsafiwgsvDNtvv33yR/773/9+0pQfzwdDuvZXvFxwwQXJeXhiwI3/GTnrrLPCdtttl5zSgcqU26677rpwxx13JOdSauz7iwdFxPOSxa+x/SC+n8X9N3jw4HDaaaclIWmfffaxy9IiV8V++tOf5saMGZPr06dPcrqA2bNnV3pItOLoo4/OjRw5MtlPW2yxRXJ97ty5tlUK3HvvvcmhyBte4mHmjacI+P73v58bPnx4clqAAw44IPfcc89VetiZ1db+WrVqVe7ggw/ObbbZZskh51tttVXuxBNPzC1cuLDSw86s1vZVvFx99dX5dd57773c17/+9dwmm2ySGzBgQO7II4/MLViwoKLjprm6+E+lwxoAQBpVZY8SAEA5CEoAAAUISgAABQhKAAAFCEoAAAUISgAABQhKAAAFCEoAAAUISgAABQhKAAAFCEoAAAUISgAAoXX/D3OPZ2iFevUNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List,Tuple,TypeAlias,Set, Dict\n",
    "from enum import Enum, auto\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters: This line is a must. The grader parser uses this line to locate the Parameters cell.\n",
    "GROUP_ID = 29\n",
    "ALGORITHM = 'ValItr'  # ValItr | QLrng | SARSA. Note that “|” denotes a choice. Only one of the choices should be provided.\n",
    "TRACK_NAME = 'tracks/U-track.txt'\n",
    "CRASH_POS = 'NRST' # NRST | STRT\n",
    "\n",
    "\n",
    "FAIL_RATE = 0.2\n",
    "START_IDX = 0\n",
    "\n",
    "# region Definitions and Setup\n",
    "Square: TypeAlias = Tuple[int, int]\n",
    "Vector: TypeAlias = Tuple[int, int]\n",
    "\n",
    "class SquareType(Enum):\n",
    "    START = auto()       # starting square ('S')\n",
    "    FINISH = auto()      # finish square ('F')\n",
    "    OPEN = auto()        # open path ('.')\n",
    "    WALL = auto()        # wall ('#')\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "CHAR_TO_TOK = {\n",
    "    'S':SquareType.START,\n",
    "    'F':SquareType.FINISH,\n",
    "    '.':SquareType.OPEN,\n",
    "    '#':SquareType.WALL\n",
    "}\n",
    "\n",
    "TOK_TO_CHAR = {k:v for v,k in CHAR_TO_TOK.items()}\n",
    "\n",
    "SQUARE_COST = {\n",
    "    SquareType.START: 1,\n",
    "    SquareType.OPEN: 1,\n",
    "    SquareType.FINISH: 0,\n",
    "    SquareType.WALL: None\n",
    "}\n",
    "# endregion\n",
    "\n",
    "# region Track and Environment Classes\n",
    "class Track:\n",
    "    def __init__(self,filename=TRACK_NAME):\n",
    "        self.state: List[List[SquareType]] = []\n",
    "        self.start_squares: List[Square] = []\n",
    "        self.finish_squares: List[Square] = []\n",
    "\n",
    "        self.parse_track(filename)\n",
    "\n",
    "    def __str__(self):\n",
    "        out = \"\"\n",
    "        for row in self.state:\n",
    "            out += ''.join([TOK_TO_CHAR[tok] for tok in row])\n",
    "            out += '\\n'\n",
    "        return out[:-1]\n",
    "\n",
    "    def parse_track(self,track):\n",
    "        with open(track, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for row,line in enumerate(lines[1:]):\n",
    "                tok_line = []\n",
    "                for col,char in enumerate(line):\n",
    "                    if char=='\\n': continue\n",
    "                    \n",
    "                    tok = CHAR_TO_TOK[char]\n",
    "                    if tok == SquareType.START: self.start_squares.append((row,col))\n",
    "                    if tok == SquareType.FINISH: self.finish_squares.append((row,col))\n",
    "                    \n",
    "                    tok_line.append(tok)\n",
    "                \n",
    "                self.state.append(tok_line)\n",
    "\n",
    "    def get_square(self,square: Square) -> SquareType:\n",
    "        return self.state[square[0]][square[1]]\n",
    "\n",
    "    def get_drivable_squares(self) -> List[Square]:\n",
    "        \"\"\"\n",
    "        Returns all squares that are not walls\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (r, c)\n",
    "            for r, row in enumerate(self.state)\n",
    "            for c, col in enumerate(row)\n",
    "            if col != SquareType.WALL\n",
    "        ]\n",
    "\n",
    "    def get_start_squares(self) -> List[Square]:\n",
    "        return self.start_squares\n",
    "\n",
    "    def is_square_finish(self, square: Square) -> bool:\n",
    "        return self.get_square(square) == SquareType.FINISH\n",
    "\n",
    "\n",
    "    def is_square_drivable(self,square: Square) -> bool:\n",
    "        r, c = square\n",
    "        if r < 0 or r >= len(self.state):\n",
    "            return False\n",
    "        if c < 0 or c >= len(self.state[0]):\n",
    "            return False\n",
    "        return self.get_square(square) != SquareType.WALL\n",
    "\n",
    "class RaceTrackEnv:\n",
    "    def __init__(self, track: None|Track = None,starting_square: Square = None):\n",
    "        self.track:        Track = track or Track()\n",
    "        self.position:     Square = starting_square or self.track.start_squares[START_IDX]\n",
    "        self.velocity:     Vector = (0,0)\n",
    "        self.acceleration: Vector = (0,0)\n",
    "\n",
    "    def stop(self):\n",
    "        self.acceleration = self.velocity = (0,0)\n",
    "\n",
    "    def reset(self, position: Square):\n",
    "        self.stop()\n",
    "        self.position = position\n",
    "\n",
    "    @staticmethod\n",
    "    def cap_velocity(velocity: Vector) -> Vector:\n",
    "        return tuple(min(5,max(-5,val)) for val in velocity)\n",
    "\n",
    "    @staticmethod\n",
    "    def bresenham_line(pos1: Square, pos2: Square) -> List[Square]:\n",
    "        \"\"\"Generate all points along a line using Bresenham's algorithm\"\"\"\n",
    "\n",
    "        points = []\n",
    "\n",
    "        x0, y0 = pos1\n",
    "        x1, y1 = pos2\n",
    "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
    "        sx = 1 if x0 < x1 else -1\n",
    "        sy = 1 if y0 < y1 else -1\n",
    "        err = dx - dy\n",
    "\n",
    "        x, y = x0, y0\n",
    "        while True:\n",
    "            points.append((x, y))\n",
    "            if x == x1 and y == y1:\n",
    "                break\n",
    "            e2 = 2 * err\n",
    "            if e2 > -dy:\n",
    "                err -= dy\n",
    "                x += sx\n",
    "            if e2 < dx:\n",
    "                err += dx\n",
    "                y += sy\n",
    "\n",
    "        return points\n",
    "\n",
    "    def do_crash(self,position: Square,crash_position: str):\n",
    "        \"\"\"\n",
    "        Handles the crash based on the crash_position policy.\n",
    "        crash_position: 'NRST' | 'STRT'\n",
    "        1. 'NRST': Move to the nearest square.\n",
    "        2. 'STRT': Move to the starting square used at the beginning of the race\n",
    "        \"\"\"\n",
    "        if crash_position == 'NRST':\n",
    "            nearest_start = min(self.track.get_drivable_squares(), key=lambda sq: (sq[0]-position[0])**2 + (sq[1]-position[1])**2)\n",
    "            self.reset(nearest_start)\n",
    "        elif crash_position == 'STRT':\n",
    "            self.reset(self.track.start_squares[START_IDX])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid crash_position policy: {crash_position}\")\n",
    "\n",
    "    def check_crash(self,target_square: Square) -> Square|None:\n",
    "        \"\"\"\n",
    "        Check if moving along a line from current position to target crashes into an obstacle.\n",
    "        Uses Bresenham's line algorithm to trace the path.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get all points along the path\n",
    "        path_points = self.bresenham_line(\n",
    "            self.position, target_square\n",
    "        )\n",
    "        # Check each point for collision\n",
    "        for sq in path_points:\n",
    "            if not self.track.is_square_drivable(sq):\n",
    "                return sq  # Crash detected\n",
    "        return None  # No crash\n",
    "\n",
    "    @staticmethod\n",
    "    def check_failure(fail_rate: float) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if the action fails based on the fail_rate.\n",
    "        \"\"\"\n",
    "        if random.random() < fail_rate:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def check_finish(self) -> bool:\n",
    "        return self.track.is_square_finish(self.position)\n",
    "\n",
    "    def step(self,acceleration: Vector,fail_rate=FAIL_RATE,crash_position=CRASH_POS):\n",
    "        \"\"\"\n",
    "        Perform a step in the environment given an acceleration.\n",
    "        `Note velocity values are capped to [-5,5]`\n",
    "        acceleration: Tuple[int,int] where each value is in [-1,0,1]\n",
    "        fail_rate: Probability of action failure.\n",
    "        crash_position: 'NRST' | 'STRT' policy for handling crashes.\n",
    "        Returns: None\n",
    "        \"\"\"\n",
    "        if not all(a in [-1,0,1] for a in acceleration):\n",
    "            raise ValueError(f\"Invalid acceleration: {acceleration}\")\n",
    "        \n",
    "        do_accel = True\n",
    "        if self.check_failure(fail_rate): do_accel = False\n",
    "        if do_accel:\n",
    "            self.acceleration = acceleration\n",
    "        \n",
    "        self.velocity = self.cap_velocity((self.velocity[0]+self.acceleration[0],self.velocity[1]+self.acceleration[1]))\n",
    "        target_position = (self.position[0]+self.velocity[0],self.position[1]+self.velocity[1])\n",
    "\n",
    "        crash = self.check_crash(target_position)\n",
    "        if not crash: self.position = target_position\n",
    "        else: self.do_crash(crash,crash_position)\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region Model Based\n",
    "State: TypeAlias = Tuple[Square,Vector]\n",
    "\n",
    "class MDPModel:\n",
    "    \"\"\"\n",
    "    For use with ValueIterationAgent\n",
    "    \"\"\"\n",
    "    def __init__(self, track: Track|None = None):\n",
    "        # List / iterable of all states in the MDP\n",
    "        self.track = track or Track()\n",
    "        self.states: Set[State] = set([\n",
    "            (square, (vx, vy))\n",
    "            for square in self.track.get_drivable_squares()\n",
    "            for vx in range(-5, 6)\n",
    "            for vy in range(-5, 6)\n",
    "        ])\n",
    "        self.crash_cache: Dict[(Square,Square):Square] = {}\n",
    "        self.transitions: Dict[(State, Vector):List[(State, float)]] = {\n",
    "            (state,action):self.compute_transition_states_and_probs(state,action)\n",
    "            for state in tqdm(self.states,desc=\"Computing Transitions\")\n",
    "            for action in self.get_possible_actions()\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def cap_velocity(velocity: Vector) -> Vector:\n",
    "        return tuple(min(5,max(-5,val)) for val in velocity)\n",
    "\n",
    "    @staticmethod\n",
    "    def bresenham_line(pos1: Square, pos2: Square) -> List[Square]:\n",
    "        \"\"\"Generate all points along a line using Bresenham's algorithm\"\"\"\n",
    "\n",
    "        points = []\n",
    "\n",
    "        x0, y0 = pos1\n",
    "        x1, y1 = pos2\n",
    "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
    "        sx = 1 if x0 < x1 else -1\n",
    "        sy = 1 if y0 < y1 else -1\n",
    "        err = dx - dy\n",
    "\n",
    "        x, y = x0, y0\n",
    "        while True:\n",
    "            points.append((x, y))\n",
    "            if x == x1 and y == y1:\n",
    "                break\n",
    "            e2 = 2 * err\n",
    "            if e2 > -dy:\n",
    "                err -= dy\n",
    "                x += sx\n",
    "            if e2 < dx:\n",
    "                err += dx\n",
    "                y += sy\n",
    "\n",
    "        return points\n",
    "\n",
    "    def check_crash(self, start_square: Square, target_square: Square) -> Square | None:\n",
    "        \"\"\"\n",
    "        Check if moving along a line from start_square to target_square crashes into an obstacle.\n",
    "        Uses Bresenham's line algorithm to trace the path.\n",
    "        Returns the first crash square, or None if no crash.\n",
    "        \"\"\"\n",
    "        path = (start_square, target_square)\n",
    "        if path in self.crash_cache:\n",
    "            return self.crash_cache[path]\n",
    "\n",
    "        path_points = self.bresenham_line(start_square, target_square)\n",
    "\n",
    "        crash_square = None\n",
    "        for sq in path_points:\n",
    "            if not self.track.is_square_drivable(sq):\n",
    "                crash_square = sq\n",
    "                break\n",
    "\n",
    "        self.crash_cache[path] = crash_square\n",
    "        return crash_square\n",
    "\n",
    "    def do_crash(self, position: Square,crash_position: str):\n",
    "        if crash_position == 'NRST':\n",
    "            nearest_start = min(self.track.get_drivable_squares(), key=lambda sq: (sq[0]-position[0])**2 + (sq[1]-position[1])**2)\n",
    "            return nearest_start\n",
    "        elif crash_position == 'STRT':\n",
    "            return self.track.start_squares[START_IDX]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid crash_position policy: {crash_position}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_possible_actions() -> List[Vector]:\n",
    "        \"\"\"\n",
    "        Actions are accelerations in this problem.\n",
    "        :return: a list of possible actions (acceleration values).\n",
    "        \"\"\"\n",
    "        return [(x,y) for x in [-1,0,1] for y in [-1,0,1]]\n",
    "\n",
    "    def compute_transition_states_and_probs(self, state: State, action,crash_position=CRASH_POS) -> List[Tuple[State, float]]:\n",
    "        \"\"\"\n",
    "        Return a list of (next_state, prob) pairs describing the transition\n",
    "        model P(s' | s, a).\n",
    "        \"\"\"\n",
    "        start_position,start_velocity = state\n",
    "\n",
    "        success_velocity = self.cap_velocity((start_velocity[0]+action[0],start_velocity[1]+action[1]))\n",
    "        success_position = (start_position[0]+success_velocity[0],start_position[1]+success_velocity[1])\n",
    "        crash = self.check_crash(start_position, success_position)\n",
    "        if crash:\n",
    "            success_position = self.do_crash(crash,crash_position)\n",
    "            success_velocity = (0,0)\n",
    "\n",
    "        fail_velocity = self.cap_velocity(start_velocity)\n",
    "        fail_position = (\n",
    "            start_position[0] + fail_velocity[0],\n",
    "            start_position[1] + fail_velocity[1],\n",
    "        )\n",
    "        crash = self.check_crash(start_position, fail_position)\n",
    "        if crash:\n",
    "            fail_position = self.do_crash(crash, crash_position)\n",
    "            fail_velocity = (0, 0)\n",
    "\n",
    "\n",
    "        return ([\n",
    "            ((fail_position,fail_velocity),FAIL_RATE),\n",
    "            ((success_position,success_velocity),1-FAIL_RATE)\n",
    "        ])\n",
    "\n",
    "    def get_transition_states_and_probs(self,state:State, action:Vector):\n",
    "        return self.transitions[(state,action)]\n",
    "\n",
    "    def get_cost(self, next_state):\n",
    "        \"\"\"\n",
    "        Return the immediate cost\n",
    "        \"\"\"\n",
    "        return SQUARE_COST[self.track.get_square(next_state[0])]\n",
    "\n",
    "\n",
    "class ValueIterationAgent:\n",
    "    \"\"\"\n",
    "    Classic value-iteration planner:\n",
    "    After convergence we extract a greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: MDPModel | None = None,\n",
    "                 gamma: float = 0.9,\n",
    "                 theta: float = 1e-3):\n",
    "        # Value function: dict[state] -> float\n",
    "        self.value_table: dict = {}\n",
    "        # Deterministic greedy policy: dict[state] -> action\n",
    "        self.policy: dict = {}\n",
    "\n",
    "        self.model: MDPModel | None = model\n",
    "        self.gamma: float = gamma\n",
    "        self.theta: float = theta  # convergence threshold\n",
    "\n",
    "        # If a model is already provided and has states, initialize and run VI\n",
    "        if self.model is not None and hasattr(self.model, \"states\"):\n",
    "            for s in self.model.states:\n",
    "                self.value_table[s] = 0.0\n",
    "            self.value_iteration()\n",
    "\n",
    "    def value_iteration(self):\n",
    "        assert self.model is not None, \"ValueIterationAgent: model is not set.\"\n",
    "\n",
    "        for s in getattr(self.model, \"states\", []):\n",
    "            self.value_table.setdefault(s, 0.0)\n",
    "\n",
    "        i = 0\n",
    "        initial_delta = None\n",
    "        while True:\n",
    "            delta = 0.0\n",
    "            i+=1\n",
    "            for s in self.model.states:\n",
    "                pos, vel = s\n",
    "                # Treat finish as terminal: value stays at 0\n",
    "                if self.model.track.is_square_finish(pos):\n",
    "                    new_v = 0.0\n",
    "                else:\n",
    "                    actions = self.model.get_possible_actions()\n",
    "                    if not actions:\n",
    "                        new_v = 0.0\n",
    "                    else:\n",
    "                        best_q = float(\"-inf\")\n",
    "                        for a in actions:\n",
    "                            q = 0.0\n",
    "                            for next_state, prob in self.model.get_transition_states_and_probs(s, a):\n",
    "                                r = -self.model.get_cost(next_state)\n",
    "                                q += prob * (r + self.gamma * self.value_table.get(next_state, 0.0))\n",
    "                            if q > best_q:\n",
    "                                best_q = q\n",
    "                        new_v = best_q\n",
    "\n",
    "                delta = max(delta, abs(new_v - self.value_table.get(s, 0.0)))\n",
    "                self.value_table[s] = new_v\n",
    "                if initial_delta is None:\n",
    "                    initial_delta = delta\n",
    "                \n",
    "            progress = 1 - (delta / initial_delta)\n",
    "            progress = max(0, min(progress, 1))  # clamp for safety\n",
    "\n",
    "            print(f\"Iter {i} | Delta = {delta:.6f} | Progress: {progress*100:.2f}%\")\n",
    "\n",
    "            if delta < self.theta:\n",
    "                break\n",
    "        \n",
    "        self._extract_policy()\n",
    "\n",
    "\n",
    "    def _extract_policy(self):\n",
    "        assert self.model is not None, \"ValueIterationAgent: model is not set.\"\n",
    "\n",
    "        self.policy.clear()\n",
    "        for s in self.model.states:\n",
    "            pos, vel = s\n",
    "            if self.model.track.is_square_finish(pos):\n",
    "                continue  # terminal, no action\n",
    "\n",
    "            actions = self.model.get_possible_actions()\n",
    "            if not actions:\n",
    "                continue\n",
    "\n",
    "            best_a = None\n",
    "            best_q = float(\"-inf\")\n",
    "            for a in actions:\n",
    "                q = 0.0\n",
    "                for next_state, prob in self.model.get_transition_states_and_probs(s, a):\n",
    "                    r = self.model.get_cost(next_state)\n",
    "                    q += prob * (r + self.gamma * self.value_table.get(next_state, 0.0))\n",
    "                if q > best_q:\n",
    "                    best_q = q\n",
    "                    best_a = a\n",
    "\n",
    "            self.policy[s] = best_a\n",
    "\n",
    "\n",
    "    def get_action_for(self, state):\n",
    "        \"\"\"\n",
    "        Return the greedy action for `state` according to the current policy.\n",
    "        If the state is unknown, fall back to a simple default (None).\n",
    "        \"\"\"\n",
    "        # If we don't have an explicit policy entry, we can either:\n",
    "        #  - return None\n",
    "        #  - or compute a one-step greedy action on the fly\n",
    "        if state in self.policy:\n",
    "            return self.policy[state]\n",
    "\n",
    "        if self.model is None:\n",
    "            return None\n",
    "\n",
    "        actions = self.model.get_possible_actions()\n",
    "        if not actions:\n",
    "            return None\n",
    "\n",
    "        # One-step greedy backup for unseen states\n",
    "        best_a = None\n",
    "        best_q = float(\"-inf\")\n",
    "        for a in actions:\n",
    "            q = 0.0\n",
    "            for next_state, prob in self.model.get_transition_states_and_probs(state, a):\n",
    "                r = -self.model.get_cost(next_state)\n",
    "                q += prob * (r + self.gamma * self.value_table.get(next_state, 0.0))\n",
    "            if q > best_q:\n",
    "                best_q = q\n",
    "                best_a = a\n",
    "\n",
    "        return best_a\n",
    "\n",
    "    def extract_greedy_path(self, max_steps: int = 1000) -> List[Square]:\n",
    "        \"\"\"\n",
    "        Roll out the greedy policy from the first start square.\n",
    "        Returns a list of positions (Squares).\n",
    "        \"\"\"\n",
    "        assert self.model is not None\n",
    "\n",
    "        start_square = self.model.track.start_squares[START_IDX]\n",
    "        state: State = (start_square, (0, 0))\n",
    "\n",
    "        path: List[Square] = [start_square]\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            pos, vel = state\n",
    "\n",
    "            # Stop if finish\n",
    "            if self.model.track.is_square_finish(pos):\n",
    "                break\n",
    "\n",
    "            action = self.get_action_for(state)\n",
    "\n",
    "            # Deterministic greedy next state\n",
    "            transitions = self.model.get_transition_states_and_probs(state, action)\n",
    "            next_state, _ = max(transitions, key=lambda item: item[1])\n",
    "\n",
    "            state = next_state\n",
    "            path.append(state[0])\n",
    "\n",
    "        return path\n",
    "\n",
    "\n",
    "    def stochastic_greedy_path(self, max_steps: int = 1000) -> List[Square]:\n",
    "        \"\"\"\n",
    "        Roll out the greedy policy from start_square\n",
    "        \"\"\"\n",
    "\n",
    "        state: State = (self.model.track.get_start_squares()[START_IDX], (0, 0))\n",
    "        path: List[Square] = [start_square]\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            pos, vel = state\n",
    "\n",
    "            # Stop if finish\n",
    "            if self.model.track.is_square_finish(pos):\n",
    "                break\n",
    "\n",
    "\n",
    "            action = self.get_action_for(state)\n",
    "            transitions = self.model.get_transition_states_and_probs(state, action)\n",
    "            next_state,_ = transitions[0] if random.random() < transitions[0][1] else transitions[1]\n",
    "\n",
    "            state = next_state\n",
    "            path.append(state[0]) \n",
    "        return path\n",
    "# endregion\n",
    "\n",
    "\n",
    "# region Model Free\n",
    "class SARSAAgent:\n",
    "    def __init__(self):\n",
    "        qtable = {}\n",
    "        alpha = 0\n",
    "        gamma = 0\n",
    "        epsilon = 0\n",
    "        last_state = None\n",
    "        last_action = None\n",
    "\n",
    "    def act(self,state):\n",
    "        pass\n",
    "\n",
    "    def update(self,state,action,reward,next_state,next_action):\n",
    "        pass\n",
    "\n",
    "    def best_action(self,state):\n",
    "        pass\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self):\n",
    "        qtable = {}\n",
    "        alpha = 0\n",
    "        gamma = 0\n",
    "        epsilon = 0\n",
    "\n",
    "    def act(self,state):\n",
    "        pass\n",
    "\n",
    "    def update(self,state,action,reward,next_state):\n",
    "        pass\n",
    "\n",
    "    def best_action(self,state):\n",
    "        pass\n",
    "# endregion\n",
    "\n",
    "# region Output and Metrics\n",
    "class EpisodeRunner:\n",
    "    def __init__(self):\n",
    "        env = None\n",
    "        agent = None\n",
    "        max_steps = 0\n",
    "\n",
    "    def run_episode(self,algorithm: SARSAAgent|QLearningAgent):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class MetricsLogger:\n",
    "    def __init__(self):\n",
    "        self.episodes: List[int] = []\n",
    "        self.steps: List[int] = []\n",
    "        self.rewards: List[float] = []\n",
    "\n",
    "    def log_episode(self, episode: int, steps: int, reward: float):\n",
    "        \"\"\"\n",
    "        Store metrics for a single episode.\n",
    "        \"\"\"\n",
    "        self.episodes.append(episode)\n",
    "        self.steps.append(steps)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def print_metrics(self):\n",
    "        \"\"\"\n",
    "        Print simple summary statistics over episodes.\n",
    "        \"\"\"\n",
    "        if not self.episodes:\n",
    "            print(\"No episodes logged.\")\n",
    "            return\n",
    "\n",
    "        n = len(self.episodes)\n",
    "        avg_steps = sum(self.steps) / n\n",
    "        avg_reward = sum(self.rewards) / n\n",
    "\n",
    "        print(f\"Episodes logged: {n}\")\n",
    "        print(f\"Steps per episode: mean = {avg_steps:.2f}, \"\n",
    "              f\"min = {min(self.steps)}, max = {max(self.steps)}\")\n",
    "        print(f\"Reward per episode: mean = {avg_reward:.2f}, \"\n",
    "              f\"min = {min(self.rewards):.2f}, max = {max(self.rewards):.2f}\")\n",
    "\n",
    "    def plot_path(self, track: Track, path: List[Square]):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        n_rows = len(track.state)\n",
    "        n_cols = len(track.state[0])\n",
    "\n",
    "        # Build grid image\n",
    "        grid = np.zeros((n_rows, n_cols))\n",
    "        for r, row in enumerate(track.state):\n",
    "            for c, cell in enumerate(row):\n",
    "                if cell == SquareType.WALL:\n",
    "                    grid[r, c] = 0\n",
    "                elif cell == SquareType.OPEN:\n",
    "                    grid[r, c] = 1\n",
    "                elif cell == SquareType.START:\n",
    "                    grid[r, c] = 2\n",
    "                elif cell == SquareType.FINISH:\n",
    "                    grid[r, c] = 3\n",
    "\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.imshow(grid, origin=\"upper\")\n",
    "\n",
    "        # Draw each step separately to avoid diagonal corner-cutting visuals\n",
    "        for (r1, c1), (r2, c2) in zip(path[:-1], path[1:]):\n",
    "            plt.plot([c1, c2], [r1, r2], color=\"red\", linewidth=2)\n",
    "\n",
    "        # Mark start and end\n",
    "        (sr, sc) = path[0]\n",
    "        (er, ec) = path[-1]\n",
    "        plt.scatter([sc], [sr], s=80, color=\"green\")   # start\n",
    "        plt.scatter([ec], [er], s=80, color=\"blue\")    # end\n",
    "\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title(\"Grid-Aligned Greedy Path\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "def main():\n",
    "    track = Track(TRACK_NAME)\n",
    "    model = MDPModel(track)\n",
    "    agent = ValueIterationAgent(model=model, gamma=0.9, theta=1e-3)\n",
    "\n",
    "    logger = MetricsLogger()\n",
    "\n",
    "    # (If you later run episodes with model-free methods, you'd call log_episode there.)\n",
    "    # For VI, just visualize the greedy path once:\n",
    "\n",
    "    start_square = track.start_squares[START_IDX]\n",
    "    best_path = agent.extract_greedy_path()\n",
    "\n",
    "    logger.plot_path(track, best_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
