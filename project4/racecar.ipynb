{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ffeccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Transitions: 100%|██████████| 26136/26136 [00:23<00:00, 1110.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1 | Delta = 2.091160 | Progress: 0.00%\n",
      "Iter 2 | Delta = 1.740210 | Progress: 16.79%\n",
      "Iter 3 | Delta = 1.540050 | Progress: 26.37%\n",
      "Iter 4 | Delta = 1.239300 | Progress: 40.76%\n",
      "Iter 5 | Delta = 1.114457 | Progress: 46.73%\n",
      "Iter 6 | Delta = 0.760216 | Progress: 63.68%\n",
      "Iter 7 | Delta = 0.561992 | Progress: 73.16%\n",
      "Iter 8 | Delta = 0.482845 | Progress: 76.95%\n",
      "Iter 9 | Delta = 0.430467 | Progress: 79.45%\n",
      "Iter 10 | Delta = 0.387420 | Progress: 81.51%\n",
      "Iter 11 | Delta = 0.348678 | Progress: 83.37%\n",
      "Iter 12 | Delta = 0.313811 | Progress: 85.03%\n",
      "Iter 13 | Delta = 0.282430 | Progress: 86.54%\n",
      "Iter 14 | Delta = 0.254187 | Progress: 87.89%\n",
      "Iter 15 | Delta = 0.228768 | Progress: 89.10%\n",
      "Iter 16 | Delta = 0.205891 | Progress: 90.20%\n",
      "Iter 17 | Delta = 0.185302 | Progress: 91.18%\n",
      "Iter 18 | Delta = 0.166772 | Progress: 92.07%\n",
      "Iter 19 | Delta = 0.150095 | Progress: 92.87%\n",
      "Iter 20 | Delta = 0.037028 | Progress: 98.28%\n",
      "Iter 21 | Delta = 0.007109 | Progress: 99.71%\n",
      "Iter 22 | Delta = 0.001361 | Progress: 99.98%\n",
      "Iter 23 | Delta = 0.000260 | Progress: 100.00%\n",
      "Path:  [(1, 1), (2, 1), (4, 1), (7, 1), (11, 1), (15, 2), (18, 4), (20, 7), (21, 11), (21, 15), (20, 18), (18, 20), (15, 21), (11, 21), (6, 21), (1, 20)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List,Tuple,TypeAlias,Set, Dict\n",
    "from enum import Enum, auto\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Parameters: This line is a must. The grader parser uses this line to locate the Parameters cell.\n",
    "GROUP_ID = 29\n",
    "ALGORITHM = 'ValItr'  # ValItr | QLrng | SARSA. Note that “|” denotes a choice. Only one of the choices should be provided.\n",
    "TRACK_NAME = 'tracks/U-track.txt'\n",
    "CRASH_POS = 'NRST' # NRST | STRT\n",
    "\n",
    "\n",
    "FAIL_RATE = 0.2\n",
    "START_IDX = 0\n",
    "CRASH_SENSISTIVITY = 0.75\n",
    "\n",
    "# region Definitions and Setup\n",
    "Square: TypeAlias = Tuple[int, int]\n",
    "Vector: TypeAlias = Tuple[int, int]\n",
    "\n",
    "class SquareType(Enum):\n",
    "    START = auto()       # starting square ('S')\n",
    "    FINISH = auto()      # finish square ('F')\n",
    "    OPEN = auto()        # open path ('.')\n",
    "    WALL = auto()        # wall ('#')\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "CHAR_TO_TOK = {\n",
    "    'S':SquareType.START,\n",
    "    'F':SquareType.FINISH,\n",
    "    '.':SquareType.OPEN,\n",
    "    '#':SquareType.WALL\n",
    "}\n",
    "\n",
    "TOK_TO_CHAR = {k:v for v,k in CHAR_TO_TOK.items()}\n",
    "\n",
    "SQUARE_COST = {\n",
    "    SquareType.START: 1,\n",
    "    SquareType.OPEN: 1,\n",
    "    SquareType.FINISH: 0,\n",
    "    SquareType.WALL: None\n",
    "}\n",
    "\n",
    "def bresenham_supercover(pos1: Square, pos2: Square) -> List[Square]:\n",
    "    \"\"\"\n",
    "        Classic 1-pixel-wide supercover Bresenham.\n",
    "    \"\"\"\n",
    "    x0, y0 = pos1\n",
    "    x1, y1 = pos2\n",
    "\n",
    "    dx = x1 - x0\n",
    "    dy = y1 - y0\n",
    "\n",
    "    sx = 1 if dx >= 0 else -1\n",
    "    sy = 1 if dy >= 0 else -1\n",
    "\n",
    "    dx = abs(dx)\n",
    "    dy = abs(dy)\n",
    "\n",
    "    x, y = x0, y0\n",
    "    points: List[Square] = [(x, y)]\n",
    "\n",
    "    if dx == 0 and dy == 0:\n",
    "        return points\n",
    "\n",
    "    if dx >= dy:\n",
    "        err = dx // 2\n",
    "        while x != x1:\n",
    "            err -= dy\n",
    "            if err < 0:\n",
    "                y += sy\n",
    "                points.append((x, y))\n",
    "                err += dx\n",
    "            x += sx\n",
    "            points.append((x, y))\n",
    "    else:\n",
    "        err = dy // 2\n",
    "        while y != y1:\n",
    "            err -= dx\n",
    "            if err < 0:\n",
    "                x += sx\n",
    "                points.append((x, y))\n",
    "                err += dy\n",
    "            y += sy\n",
    "            points.append((x, y))\n",
    "\n",
    "    return points\n",
    "\n",
    "def point_segment_distance(px, py, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Euclidean distance from point P to segment AB.\n",
    "    Uses projection and clamping.\n",
    "    \"\"\"\n",
    "    # Vector from A to P\n",
    "    APx = px - x1\n",
    "    APy = py - y1\n",
    "\n",
    "    # Vector A->B\n",
    "    ABx = x2 - x1\n",
    "    ABy = y2 - y1\n",
    "\n",
    "    # Project AP onto AB, normalized by |AB|^2\n",
    "    mag2 = ABx * ABx + ABy * ABy\n",
    "    if mag2 == 0:\n",
    "        # A and B are the same point\n",
    "        return math.hypot(APx, APy)\n",
    "\n",
    "    t = (APx * ABx + APy * ABy) / mag2\n",
    "    t = max(0.0, min(1.0, t))  # clamp\n",
    "\n",
    "    # Closest point on segment\n",
    "    cx = x1 + t * ABx\n",
    "    cy = y1 + t * ABy\n",
    "\n",
    "    return math.hypot(px - cx, py - cy)\n",
    "\n",
    "def bresenham_line(pos1: Square, pos2: Square, width: float = CRASH_SENSISTIVITY) -> List[Square]:\n",
    "    \"\"\"\n",
    "    Floating-width thick Bresenham line.\n",
    "    Returns unique grid squares touched by the thickened line.\n",
    "    \"\"\"\n",
    "    if width < 0:\n",
    "        raise ValueError(\"width must be >= 0\")\n",
    "\n",
    "    center_line = bresenham_supercover(pos1, pos2)\n",
    "\n",
    "    # If thin line requested\n",
    "    if width == 0.0:\n",
    "        return center_line\n",
    "\n",
    "    out: Set[Square] = set()\n",
    "\n",
    "    # Convert endpoints to center coordinates\n",
    "    x1, y1 = pos1[0] + 0.5, pos1[1] + 0.5\n",
    "    x2, y2 = pos2[0] + 0.5, pos2[1] + 0.5\n",
    "\n",
    "    # Determine bounding box of candidate squares\n",
    "    min_x = min(p[0] for p in center_line) - math.ceil(width)\n",
    "    max_x = max(p[0] for p in center_line) + math.ceil(width)\n",
    "    min_y = min(p[1] for p in center_line) - math.ceil(width)\n",
    "    max_y = max(p[1] for p in center_line) + math.ceil(width)\n",
    "\n",
    "    # Check all cells within bounding rectangle\n",
    "    for x in range(min_x, max_x + 1):\n",
    "        for y in range(min_y, max_y + 1):\n",
    "            # center of this grid cell\n",
    "            cx = x + 0.5\n",
    "            cy = y + 0.5\n",
    "            d = point_segment_distance(cx, cy, x1, y1, x2, y2)\n",
    "\n",
    "            if d <= width:\n",
    "                out.add((x, y))\n",
    "\n",
    "    return list(out)\n",
    "# endregion\n",
    "\n",
    "# region Track and Environment Classes\n",
    "class Track:\n",
    "    def __init__(self,filename=TRACK_NAME):\n",
    "        self.state: List[List[SquareType]] = []\n",
    "        self.start_squares: List[Square] = []\n",
    "        self.finish_squares: List[Square] = []\n",
    "\n",
    "        self.parse_track(filename)\n",
    "\n",
    "    def __str__(self):\n",
    "        out = \"\"\n",
    "        for row in self.state:\n",
    "            out += ''.join([TOK_TO_CHAR[tok] for tok in row])\n",
    "            out += '\\n'\n",
    "        return out[:-1]\n",
    "\n",
    "    def parse_track(self,track):\n",
    "        with open(track, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for row,line in enumerate(lines[1:]):\n",
    "                tok_line = []\n",
    "                for col,char in enumerate(line):\n",
    "                    if char=='\\n': continue\n",
    "                    \n",
    "                    tok = CHAR_TO_TOK[char]\n",
    "                    if tok == SquareType.START: self.start_squares.append((row,col))\n",
    "                    if tok == SquareType.FINISH: self.finish_squares.append((row,col))\n",
    "                    \n",
    "                    tok_line.append(tok)\n",
    "                \n",
    "                self.state.append(tok_line)\n",
    "\n",
    "    def get_square(self,square: Square) -> SquareType:\n",
    "        return self.state[square[0]][square[1]]\n",
    "\n",
    "    def get_drivable_squares(self) -> List[Square]:\n",
    "        \"\"\"\n",
    "        Returns all squares that are not walls\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (r, c)\n",
    "            for r, row in enumerate(self.state)\n",
    "            for c, col in enumerate(row)\n",
    "            if col != SquareType.WALL\n",
    "        ]\n",
    "\n",
    "    def get_start_squares(self) -> List[Square]:\n",
    "        return self.start_squares\n",
    "\n",
    "    def is_square_finish(self, square: Square) -> bool:\n",
    "        return self.get_square(square) == SquareType.FINISH\n",
    "\n",
    "\n",
    "    def is_square_drivable(self,square: Square) -> bool:\n",
    "        r, c = square\n",
    "        if r < 0 or r >= len(self.state):\n",
    "            return False\n",
    "        if c < 0 or c >= len(self.state[0]):\n",
    "            return False\n",
    "        return self.get_square(square) != SquareType.WALL\n",
    "\n",
    "class RaceTrackEnv:\n",
    "    def __init__(self, track: None|Track = None,starting_square: Square = None):\n",
    "        self.track:        Track = track or Track()\n",
    "        self.position:     Square = starting_square or self.track.start_squares[START_IDX]\n",
    "        self.velocity:     Vector = (0,0)\n",
    "        self.acceleration: Vector = (0,0)\n",
    "\n",
    "    def stop(self):\n",
    "        self.acceleration = self.velocity = (0,0)\n",
    "\n",
    "    def reset(self, position: Square):\n",
    "        self.stop()\n",
    "        self.position = position\n",
    "\n",
    "    @staticmethod\n",
    "    def cap_velocity(velocity: Vector) -> Vector:\n",
    "        return tuple(min(5,max(-5,val)) for val in velocity)\n",
    "\n",
    "\n",
    "    def do_crash(self,position: Square,crash_position: str):\n",
    "        \"\"\"\n",
    "        Handles the crash based on the crash_position policy.\n",
    "        crash_position: 'NRST' | 'STRT'\n",
    "        1. 'NRST': Move to the nearest square.\n",
    "        2. 'STRT': Move to the starting square used at the beginning of the race\n",
    "        \"\"\"\n",
    "        if crash_position == 'NRST':\n",
    "            nearest_start = min(self.track.get_drivable_squares(), key=lambda sq: (sq[0]-position[0])**2 + (sq[1]-position[1])**2)\n",
    "            self.reset(nearest_start)\n",
    "        elif crash_position == 'STRT':\n",
    "            self.reset(self.track.start_squares[START_IDX])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid crash_position policy: {crash_position}\")\n",
    "\n",
    "    def check_crash(self,target_square: Square) -> Square|None:\n",
    "        \"\"\"\n",
    "        Check if moving along a line from current position to target crashes into an obstacle.\n",
    "        Uses Bresenham's line algorithm to trace the path.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get all points along the path\n",
    "        path_points = bresenham_line(\n",
    "            self.position, target_square\n",
    "        )\n",
    "        # Check each point for collision\n",
    "        for sq in path_points:\n",
    "            if not self.track.is_square_drivable(sq):\n",
    "                return sq  # Crash detected\n",
    "        return None  # No crash\n",
    "\n",
    "    @staticmethod\n",
    "    def check_failure(fail_rate: float) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if the action fails based on the fail_rate.\n",
    "        \"\"\"\n",
    "        if random.random() < fail_rate:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def check_finish(self) -> bool:\n",
    "        return self.track.is_square_finish(self.position)\n",
    "\n",
    "    def step(self,acceleration: Vector,fail_rate=FAIL_RATE,crash_position=CRASH_POS):\n",
    "        \"\"\"\n",
    "        Perform a step in the environment given an acceleration.\n",
    "        `Note velocity values are capped to [-5,5]`\n",
    "        acceleration: Tuple[int,int] where each value is in [-1,0,1]\n",
    "        fail_rate: Probability of action failure.\n",
    "        crash_position: 'NRST' | 'STRT' policy for handling crashes.\n",
    "        Returns: None\n",
    "        \"\"\"\n",
    "        if not all(a in [-1,0,1] for a in acceleration):\n",
    "            raise ValueError(f\"Invalid acceleration: {acceleration}\")\n",
    "        \n",
    "        do_accel = True\n",
    "        if self.check_failure(fail_rate): do_accel = False\n",
    "        if do_accel:\n",
    "            self.acceleration = acceleration\n",
    "        \n",
    "        self.velocity = self.cap_velocity((self.velocity[0]+self.acceleration[0],self.velocity[1]+self.acceleration[1]))\n",
    "        target_position = (self.position[0]+self.velocity[0],self.position[1]+self.velocity[1])\n",
    "\n",
    "        crash = self.check_crash(target_position)\n",
    "        if not crash: self.position = target_position\n",
    "        else: self.do_crash(crash,crash_position)\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region Model Based\n",
    "State: TypeAlias = Tuple[Square,Vector]\n",
    "\n",
    "class MDPModel:\n",
    "    \"\"\"\n",
    "    For use with ValueIterationAgent\n",
    "    \"\"\"\n",
    "    def __init__(self, track: Track|None = None):\n",
    "        # List / iterable of all states in the MDP\n",
    "        self.track = track or Track()\n",
    "        self.states: Set[State] = set([\n",
    "            (square, (vx, vy))\n",
    "            for square in self.track.get_drivable_squares()\n",
    "            for vx in range(-5, 6)\n",
    "            for vy in range(-5, 6)\n",
    "        ])\n",
    "        self.crash_cache: Dict[(Square,Square):Square] = {}\n",
    "        self.transitions: Dict[(State, Vector):List[(State, float)]] = {\n",
    "            (state,action):self.compute_transition_states_and_probs(state,action)\n",
    "            for state in tqdm(self.states,desc=\"Computing Transitions\")\n",
    "            for action in self.get_possible_actions()\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def cap_velocity(velocity: Vector) -> Vector:\n",
    "        return tuple(min(5,max(-5,val)) for val in velocity)\n",
    "    \n",
    "\n",
    "\n",
    "    def check_crash(self, start_square: Square, target_square: Square) -> Square | None:\n",
    "        \"\"\"\n",
    "        Check if moving along a line from start_square to target_square crashes into an obstacle.\n",
    "        Uses Bresenham's line algorithm to trace the path.\n",
    "        Returns the first crash square, or None if no crash.\n",
    "        \"\"\"\n",
    "        path = (start_square, target_square)\n",
    "        if path in self.crash_cache:\n",
    "            return self.crash_cache[path]\n",
    "\n",
    "        path_points = bresenham_line(start_square, target_square)\n",
    "\n",
    "        crash_square = None\n",
    "        for sq in path_points:\n",
    "            if crash_square is not None: break\n",
    "            crash_square = crash_square if self.track.is_square_drivable(sq) else sq\n",
    "\n",
    "\n",
    "        self.crash_cache[path] = crash_square\n",
    "        return crash_square\n",
    "\n",
    "    def do_crash(self, position: Square,crash_position: str):\n",
    "        if crash_position == 'NRST':\n",
    "            nearest_start = min(self.track.get_drivable_squares(), key=lambda sq: (sq[0]-position[0])**2 + (sq[1]-position[1])**2)\n",
    "            return nearest_start\n",
    "        elif crash_position == 'STRT':\n",
    "            return self.track.start_squares[START_IDX]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid crash_position policy: {crash_position}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_possible_actions() -> List[Vector]:\n",
    "        \"\"\"\n",
    "        Actions are accelerations in this problem.\n",
    "        :return: a list of possible actions (acceleration values).\n",
    "        \"\"\"\n",
    "        return [(x,y) for x in [-1,0,1] for y in [-1,0,1]]\n",
    "\n",
    "    def compute_transition_states_and_probs(self, state: State, action,crash_position=CRASH_POS) -> List[Tuple[State, float]]:\n",
    "        \"\"\"\n",
    "        Return a list of (next_state, prob) pairs describing the transition\n",
    "        model P(s' | s, a).\n",
    "        \"\"\"\n",
    "        start_position,start_velocity = state\n",
    "\n",
    "        success_velocity = self.cap_velocity((start_velocity[0]+action[0],start_velocity[1]+action[1]))\n",
    "        success_position = (start_position[0]+success_velocity[0],start_position[1]+success_velocity[1])\n",
    "        crash = self.check_crash(start_position, success_position)\n",
    "        if crash:\n",
    "            success_position = self.do_crash(crash,crash_position)\n",
    "            success_velocity = (0,0)\n",
    "\n",
    "        fail_velocity = self.cap_velocity(start_velocity)\n",
    "        fail_position = (\n",
    "            start_position[0] + fail_velocity[0],\n",
    "            start_position[1] + fail_velocity[1],\n",
    "        )\n",
    "        crash = self.check_crash(start_position, fail_position)\n",
    "        if crash:\n",
    "            fail_position = self.do_crash(crash, crash_position)\n",
    "            fail_velocity = (0, 0)\n",
    "\n",
    "\n",
    "        return ([\n",
    "            ((fail_position,fail_velocity),FAIL_RATE),\n",
    "            ((success_position,success_velocity),1-FAIL_RATE)\n",
    "        ])\n",
    "\n",
    "    def get_transition_states_and_probs(self,state:State, action:Vector):\n",
    "        return self.transitions[(state,action)]\n",
    "\n",
    "    def get_cost(self, next_state):\n",
    "        \"\"\"\n",
    "        Return the immediate cost\n",
    "        \"\"\"\n",
    "        return SQUARE_COST[self.track.get_square(next_state[0])]\n",
    "\n",
    "\n",
    "class ValueIterationAgent:\n",
    "    \"\"\"\n",
    "    Classic value-iteration planner:\n",
    "    After convergence we extract a greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: MDPModel | None = None,\n",
    "                 gamma: float = 0.9,\n",
    "                 theta: float = 1e-3):\n",
    "        # Value function: dict[state] -> float\n",
    "        self.value_table: dict = {}\n",
    "        # Deterministic greedy policy: dict[state] -> action\n",
    "        self.policy: dict = {}\n",
    "\n",
    "        self.model: MDPModel | None = model\n",
    "        self.gamma: float = gamma\n",
    "        self.theta: float = theta  # convergence threshold\n",
    "\n",
    "        # If a model is already provided and has states, initialize and run VI\n",
    "        if self.model is not None and hasattr(self.model, \"states\"):\n",
    "            for s in self.model.states:\n",
    "                self.value_table[s] = 0.0\n",
    "            self.value_iteration()\n",
    "\n",
    "    def value_iteration(self, max_iterations: int = 1000):\n",
    "        assert self.model is not None\n",
    "\n",
    "        # Ensure all states are in the value table\n",
    "        for s in self.model.states:\n",
    "            self.value_table.setdefault(s, 0.0)\n",
    "\n",
    "        delta0 = None  # initial delta\n",
    "\n",
    "        for i in range(1, max_iterations + 1):\n",
    "            delta = 0.0\n",
    "\n",
    "            # ----- one sweep -----\n",
    "            for s in self.model.states:\n",
    "                pos, vel = s\n",
    "\n",
    "                if self.model.track.is_square_finish(pos):\n",
    "                    new_v = 0.0\n",
    "                else:\n",
    "                    actions = self.model.get_possible_actions()\n",
    "                    if not actions:\n",
    "                        new_v = 0.0\n",
    "                    else:\n",
    "                        best_q = float(\"-inf\")\n",
    "                        for a in actions:\n",
    "                            q = 0.0\n",
    "                            for next_state, prob in self.model.get_transition_states_and_probs(s, a):\n",
    "                                assert self.model.get_cost(next_state) is not None, f\"ValueIterationAgent: encountered invalid cost for next state {next_state}.\"\n",
    "                                r = -self.model.get_cost(next_state)\n",
    "                                q += prob * (r + self.gamma * self.value_table.get(next_state, 0.0))\n",
    "                            if q > best_q:\n",
    "                                best_q = q\n",
    "                        new_v = best_q\n",
    "\n",
    "                delta = max(delta, abs(new_v - self.value_table.get(s, 0.0)))\n",
    "                self.value_table[s] = new_v\n",
    "\n",
    "            if delta0 is None:\n",
    "                delta0 = max(delta, 1e-12)  # avoid divide-by-zero\n",
    "\n",
    "            if delta0 <= self.theta:\n",
    "                progress = 1.0\n",
    "            else:\n",
    "                progress = 1.0 - (delta - self.theta) / (delta0 - self.theta)\n",
    "                progress = max(0.0, min(1.0, progress))\n",
    "\n",
    "            print(f\"Iter {i} | Delta = {delta:.6f} | Progress: {progress*100:.2f}%\")\n",
    "\n",
    "            if delta < self.theta:\n",
    "                break\n",
    "\n",
    "        self._extract_policy()\n",
    "\n",
    "\n",
    "\n",
    "    def _extract_policy(self):\n",
    "        assert self.model is not None, \"ValueIterationAgent: model is not set.\"\n",
    "\n",
    "        self.policy.clear()\n",
    "        for s in self.model.states:\n",
    "            pos, vel = s\n",
    "            if self.model.track.is_square_finish(pos):\n",
    "                continue  # terminal, no action\n",
    "\n",
    "            actions = self.model.get_possible_actions()\n",
    "            if not actions:\n",
    "                continue\n",
    "\n",
    "            best_a = None\n",
    "            best_q = float(\"-inf\")\n",
    "            for a in actions:\n",
    "                q = 0.0\n",
    "                for next_state, prob in self.model.get_transition_states_and_probs(s, a):\n",
    "                    r = -self.model.get_cost(next_state)\n",
    "                    q += prob * (r + self.gamma * self.value_table.get(next_state, 0.0))\n",
    "                if q > best_q:\n",
    "                    best_q = q\n",
    "                    best_a = a\n",
    "\n",
    "            self.policy[s] = best_a\n",
    "\n",
    "\n",
    "    def get_action_for(self, state):\n",
    "        \"\"\"\n",
    "        Return the greedy action for `state` according to the current policy.\n",
    "        If the state is unknown, fall back to a simple default (None).\n",
    "        \"\"\"\n",
    "        if state in self.policy:\n",
    "            return self.policy[state]\n",
    "\n",
    "        if self.model is None:\n",
    "            return None\n",
    "\n",
    "        actions = self.model.get_possible_actions()\n",
    "        if not actions:\n",
    "            return None\n",
    "\n",
    "        best_a = None\n",
    "        best_q = float(\"-inf\")\n",
    "        for a in actions:\n",
    "            q = 0.0\n",
    "            for next_state, prob in self.model.get_transition_states_and_probs(state, a):\n",
    "                r = -self.model.get_cost(next_state)\n",
    "                q += prob * (r + self.gamma * self.value_table.get(next_state, 0.0))\n",
    "            if q > best_q:\n",
    "                best_q = q\n",
    "                best_a = a\n",
    "\n",
    "        return best_a\n",
    "\n",
    "    def extract_greedy_path(self, max_steps: int = 1000) -> List[Square]:\n",
    "        \"\"\"\n",
    "        Roll out the greedy policy from the first start square.\n",
    "        Returns a list of positions (Squares).\n",
    "        \"\"\"\n",
    "\n",
    "        start_square = self.model.track.start_squares[START_IDX]\n",
    "        state: State = (start_square, (0, 0))\n",
    "\n",
    "        path: List[Square] = [start_square]\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            pos, vel = state\n",
    "\n",
    "            # Stop if finish\n",
    "            if self.model.track.is_square_finish(pos):\n",
    "                break\n",
    "\n",
    "            action = self.get_action_for(state)\n",
    "\n",
    "            # Deterministic greedy next state\n",
    "            transitions = self.model.get_transition_states_and_probs(state, action)\n",
    "            next_state, _ = max(transitions, key=lambda item: item[1])\n",
    "\n",
    "            state = next_state\n",
    "            path.append(state[0])\n",
    "\n",
    "        return path\n",
    "\n",
    "\n",
    "    def stochastic_greedy_path(self, max_steps: int = 1000) -> List[Square]:\n",
    "        \"\"\"\n",
    "        Roll out the greedy policy from start_square\n",
    "        \"\"\"\n",
    "\n",
    "        start_square = self.model.track.start_squares[START_IDX]\n",
    "        state: State = (start_square, (0, 0))\n",
    "\n",
    "        path: List[Square] = [start_square]\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            pos, vel = state\n",
    "\n",
    "            # Stop if finish\n",
    "            if self.model.track.is_square_finish(pos):\n",
    "                break\n",
    "\n",
    "\n",
    "            action = self.get_action_for(state)\n",
    "            transitions = self.model.get_transition_states_and_probs(state, action)\n",
    "            next_state,_ = transitions[0] if random.random() < transitions[0][1] else transitions[1]\n",
    "\n",
    "            state = next_state\n",
    "            path.append(state[0]) \n",
    "        return path\n",
    "# endregion\n",
    "\n",
    "\n",
    "# region Model Free\n",
    "class SARSAAgent:\n",
    "    def __init__(self):\n",
    "        qtable = {}\n",
    "        alpha = 0\n",
    "        gamma = 0\n",
    "        epsilon = 0\n",
    "        last_state = None\n",
    "        last_action = None\n",
    "\n",
    "    def act(self,state):\n",
    "        pass\n",
    "\n",
    "    def update(self,state,action,reward,next_state,next_action):\n",
    "        pass\n",
    "\n",
    "    def best_action(self,state):\n",
    "        pass\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self):\n",
    "        qtable = {}\n",
    "        alpha = 0\n",
    "        gamma = 0\n",
    "        epsilon = 0\n",
    "\n",
    "    def act(self,state):\n",
    "        pass\n",
    "\n",
    "    def update(self,state,action,reward,next_state):\n",
    "        pass\n",
    "\n",
    "    def best_action(self,state):\n",
    "        pass\n",
    "# endregion\n",
    "\n",
    "# region Output and Metrics\n",
    "class EpisodeRunner:\n",
    "    def __init__(self):\n",
    "        env = None\n",
    "        agent = None\n",
    "        max_steps = 0\n",
    "\n",
    "    def run_episode(self,algorithm: SARSAAgent|QLearningAgent):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class MetricsLogger:\n",
    "    def __init__(self):\n",
    "        self.episodes: List[int] = []\n",
    "        self.steps: List[int] = []\n",
    "        self.rewards: List[float] = []\n",
    "\n",
    "    def log_episode(self, episode: int, steps: int, reward: float):\n",
    "        \"\"\"\n",
    "        Store metrics for a single episode.\n",
    "        \"\"\"\n",
    "        self.episodes.append(episode)\n",
    "        self.steps.append(steps)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def print_metrics(self):\n",
    "        \"\"\"\n",
    "        Print simple summary statistics over episodes.\n",
    "        \"\"\"\n",
    "        if not self.episodes:\n",
    "            print(\"No episodes logged.\")\n",
    "            return\n",
    "\n",
    "        n = len(self.episodes)\n",
    "        avg_steps = sum(self.steps) / n\n",
    "        avg_reward = sum(self.rewards) / n\n",
    "\n",
    "        print(f\"Episodes logged: {n}\")\n",
    "        print(f\"Steps per episode: mean = {avg_steps:.2f}, \"\n",
    "              f\"min = {min(self.steps)}, max = {max(self.steps)}\")\n",
    "        print(f\"Reward per episode: mean = {avg_reward:.2f}, \"\n",
    "              f\"min = {min(self.rewards):.2f}, max = {max(self.rewards):.2f}\")\n",
    "\n",
    "    def plot_path(self, track: Track, path: List[Square]):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        n_rows = len(track.state)\n",
    "        n_cols = len(track.state[0])\n",
    "\n",
    "        # Build grid image\n",
    "        grid = np.zeros((n_rows, n_cols))\n",
    "        for r, row in enumerate(track.state):\n",
    "            for c, cell in enumerate(row):\n",
    "                if cell == SquareType.WALL:\n",
    "                    grid[r, c] = 0\n",
    "                elif cell == SquareType.OPEN:\n",
    "                    grid[r, c] = 1\n",
    "                elif cell == SquareType.START:\n",
    "                    grid[r, c] = 2\n",
    "                elif cell == SquareType.FINISH:\n",
    "                    grid[r, c] = 3\n",
    "\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.imshow(grid, origin=\"upper\")\n",
    "\n",
    "        # Draw each step separately to avoid diagonal corner-cutting visuals\n",
    "        for (r1, c1), (r2, c2) in zip(path[:-1], path[1:]):\n",
    "            plt.plot([c1, c2], [r1, r2], color=\"red\", linewidth=1)\n",
    "\n",
    "        # Mark start and end\n",
    "        (sr, sc) = path[0]\n",
    "        (er, ec) = path[-1]\n",
    "        for (r, c) in path:\n",
    "            plt.scatter([c], [r], s=20, color=\"yellow\")\n",
    "        plt.scatter([sc], [sr], s=80, color=\"green\")   # start\n",
    "        plt.scatter([ec], [er], s=80, color=\"blue\")    # end\n",
    "\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title(\"Grid-Aligned Greedy Path\")\n",
    "        plt.savefig(f\"{GROUP_ID}_{ALGORITHM}_{TRACK_NAME.split('/')[-1]}_{CRASH_POS}.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "def main():\n",
    "    track = Track(TRACK_NAME)\n",
    "    model = MDPModel(track)\n",
    "    agent = ValueIterationAgent(model=model, gamma=0.9, theta=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "    logger = MetricsLogger()\n",
    "\n",
    "\n",
    "    start_square = track.start_squares[START_IDX]\n",
    "    best_path = agent.extract_greedy_path()\n",
    "\n",
    "    print(\"Path: \", best_path)\n",
    "\n",
    "    logger.plot_path(track, best_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
