{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-27T23:20:19.275667Z",
     "start_time": "2025-10-27T23:20:17.659250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from difflib import get_close_matches\n",
    "import csv\n",
    "from typing import Any, Optional, Set, Dict\n",
    "from dataclasses import dataclass, field\n",
    "from pgmpy.readwrite import BIFReader\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import re\n",
    "\n",
    "# Parameters\n",
    "GROUP_ID = 29\n",
    "ALGORITHM = 've' # ’ve’ = Variable Elimination, ’gibbs’ = Gibbs Sampling\n",
    "NETWORK_NAME = './Networks/child.bif'\n",
    "REPORT = 'Disease' # e.g., Child: ’Disease’\n",
    "EVIDENCE_LEVEL = 'Little' # {None | Little | Moderate} for Child/Insurance\n",
    "EVIDENCE = 'LowerBodyO2=<5; RUQO2=12+; CO2Report=>=7.5; XrayReport=Asy/Patchy'\n",
    "\n",
    "\n",
    "@dataclass (frozen=True)\n",
    "class Node:\n",
    "    # name is primary key\n",
    "    name: str\n",
    "    parents: tuple\n",
    "    values: tuple\n",
    "    probability_model: Optional[np.ndarray] = field(default=None, compare=False, repr=False)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Node):\n",
    "            return self.name == other.name\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.name}: [{\", \".join(self.values)}]'\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, nodes: Set[Node] | None = None):\n",
    "        self.nodes: Set[Node] = nodes or set()\n",
    "        self.parents: Dict[Node, Set[Node]] = defaultdict(set)   # child -> {parents}\n",
    "        self.children: Dict[Node, Set[Node]] = defaultdict(set)  # parent -> {children}\n",
    "        self.by_name: Dict[str, Node] = {}\n",
    "\n",
    "    def add_node(self, node: Node):\n",
    "        if node.name not in self.by_name:\n",
    "            self.by_name[node.name] = node\n",
    "            self.nodes.add(node)\n",
    "\n",
    "    def add_edge(self, parent_name: str, child_name: str):\n",
    "        parent = self.by_name[parent_name]\n",
    "        child = self.by_name[child_name]\n",
    "        self.parents[child].add(parent)\n",
    "        self.children[parent].add(child)\n",
    "\n",
    "    def markov_blanket(self, node: Node) -> Set[Node]:\n",
    "        blanket: Set[Node] = self.parents.get(node, set())\n",
    "        children = self.children.get(node, set())\n",
    "        blanket.update(children)\n",
    "        # children's parents excluding self\n",
    "        for child in children:\n",
    "            blanket.update(parent for parent in self.parents.get(child, set()) if parent is not node)\n",
    "        blanket.discard(node)\n",
    "        return blanket\n",
    "\n",
    "    def degree(self, node: Node) -> int:\n",
    "        return len(self.parents[node])+len(self.children[node])\n",
    "\n",
    "    def topological_order(self):\n",
    "        degree_in_context = {node:len(self.parents[node]) for node in self.nodes}\n",
    "        node_queue = deque(sorted(self.nodes, key=lambda node: degree_in_context[node]))\n",
    "\n",
    "        output = []\n",
    "        while node_queue:\n",
    "            current_node = node_queue.pop()\n",
    "            if degree_in_context[current_node] == 0:\n",
    "                output.append(current_node)\n",
    "                for child in self.children[current_node]:\n",
    "                    degree_in_context[child] -= 1\n",
    "            else:\n",
    "                node_queue.appendleft(current_node)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join(str(n) for n in sorted(self.nodes, key=lambda n: n.name))\n",
    "\n",
    "\n",
    "class InputReader:\n",
    "    def __init__(self):\n",
    "        reader = BIFReader(NETWORK_NAME)\n",
    "        model = reader.get_model()\n",
    "        states = reader.get_states()\n",
    "        net = Network()\n",
    "\n",
    "        # get all nodes\n",
    "        for variable in model.nodes():\n",
    "            cpd = model.get_cpds(variable)\n",
    "            net.add_node(Node(\n",
    "                name=str(variable),\n",
    "                parents=tuple(cpd.get_evidence() or tuple()),\n",
    "                values=tuple(states[variable]),\n",
    "                probability_model=cpd.values\n",
    "            ))\n",
    "\n",
    "        # 2) get all edges\n",
    "        for child in model.nodes():\n",
    "            cpd = model.get_cpds(child)\n",
    "            for parent in (cpd.get_evidence() or []):\n",
    "                net.add_edge(str(parent), str(child))\n",
    "\n",
    "        self.network = net\n",
    "\n",
    "        # Evidence Parser\n",
    "        self.parsed_evidence = {}\n",
    "\n",
    "        evidence = EVIDENCE.split(\";\")\n",
    "        for statement in evidence:\n",
    "            i = statement.find('=')\n",
    "            key = statement[:i].strip()\n",
    "            value = statement[i+1:].strip()\n",
    "            if key not in self.network.by_name:\n",
    "                raise(Exception(\"Invalid Evidence \"+key))\n",
    "            self.parsed_evidence[key] = value\n",
    "\n",
    "class Factor:\n",
    "    def __init__(self, variables, values):\n",
    "        \"\"\"\n",
    "        variables: list[str] in the order of axes of `values`\n",
    "        values: np.ndarray with one axis per variable (same order)\n",
    "        \"\"\"\n",
    "        self.variables = list(variables)\n",
    "        self.values = np.array(values, dtype=float)\n",
    "        assert self.values.ndim == len(self.variables), \\\n",
    "            \"values axes must match number of variables\"\n",
    "\n",
    "\n",
    "\n",
    "    def restrict(self, var, value_index):\n",
    "        if var not in self.variables:\n",
    "            return self\n",
    "        ax = self.variables.index(var)\n",
    "        # Take the slice and drop that axis\n",
    "        self.values = np.take(self.values, indices=value_index, axis=ax)\n",
    "        self.variables.pop(ax)\n",
    "        return self\n",
    "\n",
    "    def _align_to(self, all_vars):\n",
    "        \"\"\"\n",
    "        Return a view of self.values whose axes are placed at the positions\n",
    "        matching all_vars; missing variables are broadcast via singleton axes.\n",
    "        \"\"\"\n",
    "        # Where each of our variables should go in all_vars\n",
    "        dest_axes = [all_vars.index(v) for v in self.variables]\n",
    "\n",
    "        # Ensure we have enough axes to move: pad with singleton axes at the end\n",
    "        arr = self.values\n",
    "        need = len(all_vars) - arr.ndim\n",
    "        if need > 0:\n",
    "            arr = arr.reshape(arr.shape + (1,) * need)\n",
    "\n",
    "        # Move our current axes (0..k-1) to their destination positions\n",
    "        arr = np.moveaxis(arr, list(range(len(self.variables))), dest_axes)\n",
    "        return arr\n",
    "\n",
    "    def multiply(self, other):\n",
    "        \"\"\"\n",
    "        Pointwise multiply with broadcasting after aligning axes by variable name.\n",
    "        \"\"\"\n",
    "        # Stable union order: keep self order, then add other's new vars\n",
    "        all_vars = list(dict.fromkeys(self.variables + other.variables))\n",
    "\n",
    "        A = self._align_to(all_vars)\n",
    "        B = other._align_to(all_vars)\n",
    "\n",
    "        # Now A and B have the same ndim and compatible shapes\n",
    "        prod = A * B\n",
    "        return Factor(all_vars, prod)\n",
    "\n",
    "    def sum_out(self, var):\n",
    "        if var not in self.variables:\n",
    "            return self\n",
    "        ax = self.variables.index(var)\n",
    "        self.values = self.values.sum(axis=ax)\n",
    "        self.variables.pop(ax)\n",
    "        return self\n",
    "\n",
    "    def normalize(self):\n",
    "        Z = self.values.sum()\n",
    "        if Z != 0:\n",
    "            self.values = self.values / Z\n",
    "        return self\n",
    "\n",
    "\n",
    "class VESolver:\n",
    "\n",
    "    @staticmethod\n",
    "    def _value_index(node, label: str) -> int:\n",
    "        # exact or case-insensitive\n",
    "        try:\n",
    "            return node.values.index(label)\n",
    "        except ValueError:\n",
    "            lower_vals = [s.lower() for s in node.values]\n",
    "            try:\n",
    "                return lower_vals.index(label.lower())\n",
    "            except ValueError:\n",
    "                allowed = \", \".join(node.values)\n",
    "                raise ValueError(f\"Value {label!r} invalid for {node.name}. \"\n",
    "                                 f\"Allowed: [{allowed}]\")\n",
    "\n",
    "\n",
    "    # ---------- factor creation ----------\n",
    "    def _factor_from_node(self, network, node) -> \"Factor\":\n",
    "        \"\"\"\n",
    "        Reshape node.probability_model (pgmpy CPD values) from\n",
    "        (child_card, prod(parent_cards)) -> (child_card, *parent_cards)\n",
    "        following the exact parent order in node.parents.\n",
    "        \"\"\"\n",
    "        child = node.name\n",
    "        parents = list(node.parents or ())\n",
    "        variables = [child] + parents\n",
    "        child_card = len(network.by_name[child].values)\n",
    "        parent_cards = [len(network.by_name[p].values) for p in parents]\n",
    "\n",
    "        vals = np.array(node.probability_model, dtype=float).reshape(\n",
    "            (child_card, *parent_cards),\n",
    "            order=\"F\"  # pgmpy stores evidence columns in Fortran order\n",
    "        )\n",
    "        return Factor(variables, vals)\n",
    "\n",
    "    def _build_factors(self, network) -> list[\"Factor\"]:\n",
    "        return [self._factor_from_node(network, n) for n in network.nodes]\n",
    "\n",
    "    def solve(self, network, query: str, evidence: dict[str, str]):\n",
    "        # dict of labels: map to indices\n",
    "        evidence_node_states = {}\n",
    "\n",
    "        for variable in evidence:\n",
    "            evidence_node_states[variable] = network.by_name[variable].values.index(evidence[variable])\n",
    "\n",
    "        # factors\n",
    "        factors = self._build_factors(network)\n",
    "\n",
    "        # restrict evidence\n",
    "        for variable, state in evidence_node_states.items():\n",
    "            for factor in factors:\n",
    "                factor.restrict(variable, state)\n",
    "\n",
    "        elim_order = [node.name for node in network.topological_order() if node.name != query]\n",
    "\n",
    "        # eliminate\n",
    "        for eliminating_variable in elim_order:\n",
    "            bucket = [factor for factor in factors if eliminating_variable in factor.variables]\n",
    "            if not bucket:\n",
    "                continue\n",
    "            new_f = bucket[0]\n",
    "            for f in bucket[1:]:\n",
    "                new_f = new_f.multiply(f)\n",
    "            new_f.sum_out(eliminating_variable)\n",
    "            # replace bucket with new_f\n",
    "            factors = [f for f in factors if f not in bucket] + [new_f]\n",
    "\n",
    "        # multiply remaining & normalize\n",
    "        result = factors[0]\n",
    "        for f in factors[1:]:\n",
    "            result = result.multiply(f)\n",
    "        result.normalize()\n",
    "\n",
    "        # result should be a factor over [query] (possibly with size-1 evidence axes)\n",
    "        # If extra singleton axes remain, drop them until only query remains.\n",
    "        while result.variables != [query]:\n",
    "            # remove any size-1 axes by summing (no-op) or squeezing safely\n",
    "            for variable in list(result.variables):\n",
    "                if variable != query and result.values.shape[result.variables.index(variable)] == 1:\n",
    "                    result.sum_out(variable)\n",
    "                    break\n",
    "            else:\n",
    "                # ff we get here, there are still other vars present; multiply must have left something\n",
    "                break\n",
    "\n",
    "        print(REPORT+\":\")\n",
    "        print(\" \".join(network.by_name[REPORT].values))\n",
    "        print(\" \".join([f\"{val:.2f}\" for val in result.values]))\n",
    "        return result\n",
    "\n",
    "class GibbsSolver:\n",
    "    def solve(self,network: Network):\n",
    "        pass\n",
    "\n",
    "class OutputWriter:\n",
    "    def __init__(self,solver):\n",
    "        with open(f\"{GROUP_ID}_{ALGORITHM}_{NETWORK_NAME}_{EVIDENCE_LEVEL}.csv\", 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "class Driver:\n",
    "    def __init__(self):\n",
    "        self.reader = InputReader()\n",
    "        match(ALGORITHM.lower()):\n",
    "            case \"ve\":\n",
    "                self.solver = VESolver()\n",
    "            case \"gibbs\":\n",
    "                self.solver = GibbsSolver()\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        factor = self.solver.solve(self.reader.network,REPORT,self.reader.parsed_evidence)\n",
    "\n",
    "\n",
    "        # OutputWriter(self.solver)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Driver()\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease:\n",
      "PFC TGA Fallot PAIVS TAPVD Lung\n",
      "0.03 0.29 0.29 0.28 0.08 0.03\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
